---
title             : "What we do (not) know about the mechanisms underlying adaptive speech perception: A computational framework and review"
shorttitle        : "Exposure effects in speech perception"
date              : "`r format(Sys.time(), '%B %d, %Y')`"

author: 
  - name          : "Xin Xie"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "3151 Social Science Plaza B, University of California, Irvine CA 92697–5100"
    email         : "xxie14@uci.edu"
    # role: 
    #   - Conceptualization
    #   - Writing - Original Draft Preparation
    #   - Writing - Review & Editing
    #   - Coding of analyses and visualization
  - name          : "T. Florian Jaeger"
    affiliation   : "2,3"
    # role:
    #   - Conceptualization
    #   - Writing - Original Draft Preparation
    #   - Writing - Review & Editing
    #   - Coding of analyses and visualization
  - name          : "Chigusa Kurumada"
    affiliation   : "2"
    # role:
    #   - Conceptualization & Framing
    #   - Writing - Original Draft Preparation
    #   - Writing - Review & Editing
    #   - Visualization

affiliation:
  - id            : "1"
    institution   : "Language Science, University of California, Irvine"
  - id            : "2"
    institution   : "Brain and Cognitive Sciences, University of Rochester"
  - id            : "3"
    institution   : "Computer Science, University of Rochester"

authornote: |
  We are grateful to Meghan Clayards and Eleanor Chodroff for sharing their data in an accessible format, and for helping prepare their data for this study. We thank the participants in the 2021 summer 'mega-lab' meetings for many insightful discussions that shaped the perspectives discussed here (all mistakes remain our own). This includes, in particular, Ann Bradlow, Melissa Baese-Berk, Eleanor Chodroff, Jennifer Cole, Laura Dilley, James McQueen, Arty Samuel, and Rachel Theodore. We also owe special thanks, and insights, to feedback from Marc Allassonnière-Tang, Zach Burchill, Wednesday Bushong, Shawn Cummings, Seth Cutler, Volya Kapatsinski, Jing Liu, Gerda Melnik, Anna Persson, Paula Rubio Fernandez, and Rachel Sabatello. Finally, we thank the reviewers and editors who provided particularly constructive critiques, gave us room to develop our ideas, and showed patience throughout the process of preparing and improving this manuscript.

abstract: |
  Speech from unfamiliar talkers can be difficult to comprehend initially. These difficulties tend to dissipate with exposure, sometimes within minutes or less. Adaptivity in response to unfamiliar input is now considered a fundamental property of speech perception, and research over the past two decades has made substantial progress in identifying its characteristics. The *mechanisms* underlying adaptive speech perception, however, remain unknown. Past work has attributed facilitatory effects of exposure to any one of three qualitatively different hypothesized mechanisms: (1) low-level, pre-linguistic, signal normalization, (2) changes in/selection of linguistic representations, or (3) changes in post-perceptual decision-making. Direct comparisons of these hypotheses, or combinations thereof, have been lacking. We describe a general computational framework for adaptive speech perception (ASP) that---for the first time---implements all three mechanisms. We demonstrate how the framework can be used to derive predictions for experiments on perception from the acoustic properties of the stimuli. Using this approach, we find that---at the level of data analysis presently employed by most studies in the field---the signature results of influential experimental paradigms do not distinguish between the three mechanisms. This highlights the need for a change in research practices, so that future experiments provide more informative results. We recommend specific changes to experimental paradigms and data analysis. All data and code for this study are shared via OSF, including the R markdown document that this article is generated from, and an R library that implements the models we present.
  
keywords          : "speech perception; computational model; accent adaptation; perceptual recalibration"
# wordcount         : "X"

bibliography      : ["latex-stuff/library.bib", "latex-stuff/r-references.bib"]
link-citations    : yes
csl               : latex-stuff/apa-6th-edition.csl

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
numbersections    : false
mask              : no
draft             : no

header-includes: 
 - \usepackage{animate}
 - \usepackage{amsmath}
 - \usepackage{tikz}
 - \usetikzlibrary{bayesnet}
 - \usepackage{booktabs}
 - \usepackage{siunitx}
 - \usepackage{soul}
 - \usepackage{tabto}
 - \usepackage{xcolor}
 - \usepackage{placeins}
 - \setstcolor{red}
 - \usepackage{sectsty}
 - \sectionfont{\color{black}}
 - \subsectionfont{\color{black}}
 - \subsubsectionfont{\color{black}}
 - \usepackage{setspace}\doublespacing
 - \usepackage[labelformat=simple]{subcaption}
 - \usepackage{hyperref}

documentclass     : "apa6"
classoption       : "man"
fontsize          : 11pt
output: 
  papaja::apa6_pdf:
    latex_engine: xelatex
    includes:
      in_header: latex-stuff/header.tex
    keep_tex: yes
    citation_package: biblatex
    extra_dependencies: "subfig" 
always_allow_html: true
---

\setcounter{secnumdepth}{5}
\renewcommand{\thesubfigure}{\textbf{\Alph{subfigure})}}

```{r functions-general, include=FALSE, message=FALSE}
get_path <- function(filename) return(paste0("", filename))

source("libraries.R")
source("functions.R")
source("constants.R")
options(dplyr.summarise.inform = FALSE)
# Get citation information
r_refs(file = "latex-stuff/r-references.bib")
```

```{r knitr-setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, message = FALSE, warning = TRUE, 
  results = "markup", cache = TRUE,
  interval = .2,
  fig.path = get_path("../figures/knitted/"), fig.align = "center", fig.height = 2.5, fig.width = 2.5)

knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark=",") })

knitr::knit_hooks$set(document = function(x) {sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)})
color_block = function(color) { function(x, options) sprintf('\\color{%s}\\begin{verbatim}%s\\end{verbatim}\\color{black}', color, x) }
knitr::knit_hooks$set(error = color_block('red'))
knitr::knit_hooks$set(warning = color_block('orange'))
```

```{r analysis-preferences}
INCLUDE_TODO = F        # switch on/off to get to do list.
SET_SEED = T            # switch on/off whether the same seed is set every time a randomization procedure is called
ANIMATE_FIGURES = F     # switch on/off to replace animations with facets
SAVE_ANIMATED_VIDEO = F # switch on/off to save animations as videos (e.g., mp4, webm)
RESET_FIGURES = F       # switch on/off whether time-consuming 3D figures are re-run and overridden
RESET_MODELS = F        # switch on/off whether model optimization etc. is re-run even if it's already in the repo 
                        # (this will take a long time to run [many hours])

# Seed for random number generation
if (SET_SEED) set.seed(42007)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

# Figure and figure font sizing for results figures
convert_fontsize_to_textsize <- function(x) x * 5/14
convert_cm_to_inch <- function(x) x / 2.54

result.panel.size <- convert_cm_to_inch(2.5)
result.base.size <- 8

phonetic.panel.width <- convert_cm_to_inch(2.625)
phonetic.panel.height <- convert_cm_to_inch(2.25)
phonetic.base.size <- 7.5

duo.panel.key <- unit(0.2, 'cm')
```

```{r, child="section-0-TO-DO.Rmd", eval= if (INCLUDE_TODO) TRUE else FALSE}
```

\brefsection

```{r, child="section-1-introduction.Rmd"}
```

```{r, child="section-2-framework.Rmd", eval=TRUE}
```

```{r, child="section-3-overview-case-studies.Rmd", eval=TRUE}
```

```{r, child="section-4-perceptual-recalibration.Rmd", eval=TRUE}
```

```{r, child="section-5-accent-adaptation.Rmd", eval=TRUE}
```

```{r, child="section-6-general-discussion.Rmd", eval=TRUE}
```

\printbibliography
\erefsection

\brefsection

```{r, child="supplementary-information.Rmd", eval=TRUE}
```

\printbibliography
\erefsection
