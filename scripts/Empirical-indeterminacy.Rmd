---
title             : "What we do (not) know about the mechanisms underlying adaptive speech perception: A computational framework and review"
shorttitle        : "Exposure effects in speech perception"
date              : "`r format(Sys.time(), '%B %d, %Y')`"

author: 
  - name          : "Xin Xie"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "3151 Social Science Plaza B, University of California, Irvine CA 92697–5100"
    email         : "xxie14@uci.edu"
    # role: 
    #   - Conceptualization
    #   - Writing - Original Draft Preparation
    #   - Writing - Review & Editing
    #   - Coding of analyses and visualization
  - name          : "T. Florian Jaeger"
    affiliation   : "2,3"
    # role:
    #   - Conceptualization
    #   - Writing - Original Draft Preparation
    #   - Writing - Review & Editing
    #   - Coding of analyses and visualization
  - name          : "Chigusa Kurumada"
    affiliation   : "2"
    # role:
    #   - Conceptualization & Framing
    #   - Writing - Original Draft Preparation
    #   - Writing - Review & Editing
    #   - Visualization

affiliation:
  - id            : "1"
    institution   : "Language Science, University of California, Irvine"
  - id            : "2"
    institution   : "Brain and Cognitive Sciences, University of Rochester"
  - id            : "3"
    institution   : "Computer Science, University of Rochester"

authornote: |
  We are grateful to ### ommitted for review ###
# Meghan Clayards and Eleanor Chodroff for sharing their data in an accessible format, and for helping prepare their data for this study. We thank the participants in the 2021 summer 'mega-lab' meetings for many insightful discussions that shaped the perspectives discussed here (all mistakes remain our own). This includes, in particular, Ann Bradlow, Melissa Baese-Berk, Eleanor Chodroff, Jennifer Cole, Shawn Cummings, Laura Dilley, James McQueen, Arty Samuel, Maryann Tan, and Rachel Theodore. We also owe many thanks for early feedback on this project to Marc Allassonnière-Tang, Seth Cutler, Jing Liu, Gerda Melnik, Anna Persson, Paula Rubio Fernandez, Rachel Sabatello, and Maryann Tan.

abstract: |
  Speech from unfamiliar talkers can be difficult to comprehend initially. These difficulties tend to dissipate with exposure, sometimes within minutes or less. Adaptivity in response to unfamiliar input is now considered a fundamental property of speech perception, and research over the past two decades has made substantial progress in identifying its characteristics. The *mechanisms* underlying adaptive speech perception, however, remain unknown. Past work has attributed facilitatory effects of exposure to any one of three qualitatively different hypothesized mechanisms: (1) low-level, pre-linguistic, signal normalization, (2) changes in/selection of linguistic representations, or (3) changes in post-perceptual decision-making. Direct comparisons of these hypotheses, or combinations thereof, have been lacking. We describe a general computational framework that---for the first time---implements all three mechanisms. We demonstrate how the framework can be used to derive predictions for experiments on perception from the acoustic properties of the stimuli. Using this approach, we find that---at the level of data analysis presently employed by most studies in the field---the signature results of common experimental paradigms do not distinguish between the three mechanisms. This highlights the need for a change in research practices, so that future experiments provide more informative results. We recommend specific changes to experimental paradigms and data analysis. All data and code for this study are shared via OSF, including the R markdown document that this article is generated from, and an R library that implements the models we present.
  
keywords          : "speech perception; computational model; accent adaptation; perceptual recalibration"
wordcount         : "X"

bibliography      : ["latex-stuff/library.bib", "latex-stuff/r-references.bib"]
link-citations    : yes
csl               : latex-stuff/apa-6th-edition.csl

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
numbersections    : false
mask              : no
draft             : no

header-includes: 
 - \usepackage{animate}
 - \usepackage{amsmath}
 - \usepackage{tikz}
 - \usetikzlibrary{bayesnet}
 - \usepackage{booktabs}
 - \usepackage{siunitx}
 - \usepackage{soul}
 - \usepackage{tabto}
 - \usepackage{xcolor}
 - \usepackage{placeins}
 - \setstcolor{red}
 - \usepackage{sectsty}
 - \sectionfont{\color{black}}
 - \subsectionfont{\color{black}}
 - \subsubsectionfont{\color{black}}
 - \usepackage{setspace}\doublespacing
 - \usepackage{subfig}
 - \usepackage{hyperref}

documentclass     : "apa6"
classoption       : "man"
fontsize          : 11pt
output: 
  papaja::apa6_pdf:
    latex_engine: xelatex
    extra_dependencies: "subfig" 
    includes:
      in_header: latex-stuff/header.tex
always_allow_html: true
---

\setcounter{secnumdepth}{5}

```{r functions-general, include=FALSE, message=FALSE}
get_path <- function(filename) return(paste0("", filename))

source("libraries.R")
source("functions.R")
source("constants.R")
options(dplyr.summarise.inform = FALSE)
# Get citation information
r_refs(file = "latex-stuff/r-references.bib")
```

```{r knitr-setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, message = FALSE, warning = TRUE, 
  results = "markup", cache = TRUE,
  interval = .2,
  fig.path = get_path("../figures/knitted/"), fig.align = "center", fig.height = 2.5, fig.width = 2.5)

knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark=",")
})

knitr::knit_hooks$set(document = function(x) {sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)})
color_block = function(color) { function(x, options) sprintf('\\color{%s}\\begin{verbatim}%s\\end{verbatim}\\color{black}', color, x) }
knitr::knit_hooks$set(error = color_block('red'))
knitr::knit_hooks$set(warning = color_block('orange'))
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42007)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

SET_SEED = T         # switch on/off whether the same seed is set every time a randomization procedure is called
RESET_MODELS = F     # switch on/off whether model optimization etc. is re-run even if it's already in the repo
```

```{r, child="section-0-TO-DO.Rmd", eval= if (TODO) TRUE else FALSE}
```

<!-- Using inline R markdown child definition since only the quiet = T option oppresses both the latex *and* the R output of a child -->

```{r, child="section-1-introduction.Rmd"}
```

```{r, child="section-2-framework.Rmd", eval=TRUE}
```

```{r, child="section-3-perceptual-recalibration.Rmd", eval=TRUE}
```

```{r, child="section-4-accent-adaptation.Rmd", eval=TRUE}
```

```{r, child="section-5-distributional-learning.Rmd", eval=FALSE}
```

```{r, child="section-6-general-discussion.Rmd", eval=TRUE}
```

```{r, child="section-7-references.Rmd", eval=TRUE}
```

```{r, child="supplementary-information.Rmd", eval=TRUE}
```


