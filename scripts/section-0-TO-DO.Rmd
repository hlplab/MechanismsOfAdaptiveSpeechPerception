# OPEN WORK

  * BEGINNING OF GD

# THINGS TO DO
Let's delete to-dos after they have been addressed, and post in Slack what we've done. Thanks.

  * Xin:
    *  **Relative benefit of the three models: carefully adjust the caption and main texts for case study 2 and the general discussion accordingly.**
    * CHECK ALL REMAINING TO-DO comments in the text.
    * **discuss the impact of unbalanced data on different normalization methods** (see discussion on Slack)

    
  * Xin and Chigusa:
    * I cut some passages. There are linked in this section below. Please check whether they ought to go somewhere else. If you're ok cutting them, please move them into Cutout-stuff.Rmd.


  * Florian: 
    * **discuss whether e.g., norris et al's (ambiguous nonce-word) condition rules out normalization**. If labeling makes a difference that's an issue for normalization accounts (see also goldilocks Babel et al; other results in which labeling makes a difference). **This could be framed under 'potential objections to our conclusions' where we acknowledge that there are isolated results that may be taken to argue for one account over the other; however, arguably, we would still as a field want to increase the informativeness of our studies, rather than to rely on isolated findings.
    * **Find a way to signal more clearly that we are also entertaining that combinations of mechanisms matter.**
    * CHECK OUT WHETHER CHANGES IN NORMALIZATION CAN LEAD TO NON-LINEAR CHANGES *DESPITE THE FACT THAT WE'RE USING SIMPLE LINEAR INTERPOLATION*

## Things to perhaps do later:

  * Florian
    * make a wrapper for categorization function (through optional argument) that makes the functions monotonic. do the math.

## Notes for revision

Revisions to intro:
  
1) be clearer about our contributions (indeed, the review we provide in the intro is in itself a contribution). as part of this, we are now more critical of the status quo of the field. This makes it clearer where we are coming from. But we would like to hear reviewers' thoughts on these issues.'
2) be clearer about our goals, incl. what we do and do not aim to achieve in this paper. 
3) remove unnecessary details


Revisions to Sec 2:

 * not many because we want to keep the paper tutorial-like. However, if this is an issue, we could extract that entire section and either move it into a separate paper or make it part of the SI.
 
 * We made the structure of this section clearer---dividing it into two main sections (categorization and change models), and highlighted in the introduction to the section what is new in this model and what is not. 
 
 * We made a small change to the change model for decision biases to make it more similar to one of the most common types of learning models assumed in the cognitive sciences. We now update decision biases based on the prediction error (surprisal) experienced for an observation. This model makes very similar predictions to the specific change model we used previously (because it has very similar updating mechanics) but is a bit easier to describe, and hopefully more familiar to readers.


## CUTS---PLEASE CHECK CAREFULLY AND DELETE THOSE THAT YOU THINK CAN GO



  * And while distinct normalization procedures have been compared to each other [e.g., @adank2004; @hoffmanbion-escudero2007; @kiefte-nearey2019] or against the absence of normalization [@mcmurray-jongman2011], they are rarely compared to the competing hypothesis that changes in representations underlie the effects of recent exposure [for notable exceptions, see @apfelbaum-mcmurray2015; @lehet-holt2020; @xie2021cognition]. ^[It is, however, worth pointing out that the exact nature of normalization remains unclear. This includes questions about the specific transformations that are applied [@REFS] but also questions about whether normalization is best viewed as an autonomous, encapsulated process, or as part of a larger hierarchical inference process that includes inferences at both levels traditionally considered linguistic and levels traditionally considered pre-linguistic. Research on automatic speech recognition, for example, has found that deep neural network models can to some extent remove the need for specialized signal transformations [@deng2016]. Under this view, normalization is itself the result of a hierarchical predictive process that seeks to efficiently predict the incoming signal [for related discussion, see @clark2013; @kell2018; @kleinschmidt-jaeger2015; @kuperberg-jaeger2016].] 


  * <!--leave it here for now, but potentially can be integrated into GD-->An explicit mechanistic account delineating how adaptive changes also strengthens our ability to probe its neural substrates. To date, multiple neurobiological systems have been proposed to support these rapid changes. They range from the primary auditory cortex  [e.g., Heschl’s gyrus] to those that respond to acoustic-phonetic features in speech [e.g., superior temporal gyrus, @Yi2019]. Even wider heterogeneous networks have been implicated in studies assessing brain responses to novel speech input, including those responsible for recognizing a voice/talker [@luthra2020b], attending selectively to a given talker's speech [@wong2004], and correcting prediction errors when there is a discrepancy between a predicted vs. an actual input [e.g., @guediche2015evidence], to name a few. Identifying the roles these brain regions play during adaptive speech perception is not straightforward, as these regions often play multiple roles in cognitive processing. Therefore, the exact interpretation of the findings still depends on the researchers’ hypothesis of the underlying mechanism. For instance, changes in inferior frontal gyri activation in response to accented speech has been interpreted as reflecting greater computational demand [@yi2014neural] or decision related phonetic categorization of ambiguous stimuli [@myers-mesite2014]. A proper theoretical framework that specifies how the alternative mechanisms can account for adaptive changes in speech perception, either in isolation or jointly, will facilitate the design and interpretations of neural investigations.
  
  * This doesn actually seem to be what we do:  Results of our simulations illuminate when---to what stimuli and under what circumstances---the three mechanisms would provide diverging predictions about adaptive changes of perception. We also learn about how much data will be needed to draw reliable statistical inferences from behavioral data. 
  
  * Perhaps better for discussion: Frameworks like ASP that encompasses (A)-(C) thus hold the potential to meaningfully link across multiple lines of behavioral and neuroimaging research [for a related discussion, see @guediche2014, p. 8]. 


<!-- By developing a computational framework that at least acknowledges, and integrates these aspects of speech perception, we take on (small) step towards addressing the challenge identified by @guediche2014: "there is no formal speech perception model that relates activity in the cortical regions identified via neuroimaging to the computational demands of adaptive plasticity in speech perception. Conversely, the classic computational models of speech perception that have attempted to differentiate how the system may meet the computational demands of adaptive plasticity have not made specific predictions of the underlying neural mechanisms".  -->

## Somewhere list all the factors that can determine power during test:

1. the expected change in the categorization function during exposure (describe elsewhere what this is a fucntion of)

2. the location of the test tokens

3. the task used during test
3a. the lapse rate, which is a function of how boring and/or streneous the task is
3b. response biases
3c. response decision criterion relaxation

4. the dependent variable
4a. the measurement noise
4b. the inherent variability

5. anything that undoes the exposure effect, limited the effective sample size.

6. the choice of analysis
6a. validity of assumptions
