# THINGS TO DO
Let's delete to-dos after they have been addressed, and post in Slack what we've done. Thanks.

  * Everyone: 
    * Should we make all parameters either 'confidence' / weight of prior knowledge OR learning rates? 

## TO DOs identified in lab mtg

 * Send paper out to emily myers and james mcqueen and ask whether they’d be willing to read this in their lab?

## Things to perhaps do later:

  * Florian
    * make a wrapper for categorization function (through optional argument) that makes the functions monotonic. do the math.
    * CHECK OUT WHETHER CHANGES IN NORMALIZATION CAN LEAD TO NON-LINEAR CHANGES *DESPITE THE FACT THAT WE'RE USING SIMPLE LINEAR INTERPOLATION*
    
  * Move the part about ASP not being a new model to the top of the intro. It may help to signal that we’re aiming to summarize what is known. (Seth)
  * (Shawn) should you highlight “how far can you push normalization before it becomes changes in representations”? (I’m inclined not to get into these nuances in this paper).
  * Can we be clearer that even if one agrees on the three mechanisms, we need to figure out how these mechanisms work. But how do we communicate this? Essentially, it became abundantly clear to us that even minute details can make a big difference in the predictions a model ends up making, so that it’s important to actually implement models. The difference between theory and model. Could go to end of intro or beginning of section 2.
  *　Consider adding a footnote in PR section that nothing would change if ambiguous tokens were taken to be identical. note also that there is no ‘true’ identity since the context changes.
