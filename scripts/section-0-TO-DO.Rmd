# THINGS TO DO
Let's delete to-dos after they have been addressed, and post in Slack what we've done. Thanks.

  * Xin:
    * fig 29:
      * check why the L2 number for the contrast reduction is 0.72 not 0.78 (previously it was)
      * make sure that best-fitting decision-making model in Fig 29 is correct (using same max sims as in the previous figures)
 
  * Everyone: 
    * Re-read Volya's comments about its relevance.
  * Send paper out to emily myers and james mcqueen and ask whether they’d be willing to read this in their lab? It's now or never.
  
## Things to perhaps do later:

  * Florian
    * make a wrapper for categorization function (through optional argument) that makes the functions monotonic. do the math.
    * CHECK OUT WHETHER CHANGES IN NORMALIZATION CAN LEAD TO NON-LINEAR CHANGES *DESPITE THE FACT THAT WE'RE USING SIMPLE LINEAR INTERPOLATION*
  * Can we be clearer that even if one agrees on the three mechanisms, we need to figure out how these mechanisms work. But how do we communicate this? Essentially, it became abundantly clear to us that even minute details can make a big difference in the predictions a model ends up making, so that it’s important to actually implement models. The difference between theory and model. Could go to end of intro or beginning of section 2.
  *　Consider adding a footnote in PR section that nothing would change if ambiguous tokens were taken to be identical. note also that there is no ‘true’ identity since the context changes.

\newpage 
