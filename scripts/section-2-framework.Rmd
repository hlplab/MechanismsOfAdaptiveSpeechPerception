# Modeling adaptive changes in speech perception  {#sec:framework}
We start by describing the computational framework. Our goal here is not to present a new model of speech perception but rather to describe a framework that i) integrates the core insights shared by present-day theories of speech perception, ii) extends these models to specify ways to think about how recent exposure can come to affect any of the three mechanistic levels, and iii) stays as simple and conceptually transparent as possible. The framework builds on a psychometric model that is used for data analysis in many areas of the cognitive sciences [for an introduction, see @wichmann-hill2001] but remains rare in research on speech perception---in particular, in research on the effects of recent experience [but see @clayards2008; @kleinschmidt-jaeger2016cogsci]. We extend this psychometric model in as few ways as necessary. Most notably, this includes the specification of competing linking hypotheses that describe the effects of recent exposure on normalization, representations, and/or response biases.

We assume conceptual familiarity with reasoning about distributions and contemporary theories of speech perception---all of which expect that listeners have implicit representations of the mapping between phonetic cues and linguistic categories that encompass (in one or the other form) knowledge of the distribution of cues that correspond to a linguistic category. This logic is motivated by observations such as shown in Figure \@ref(fig:schertzclare) [reprinted from @schertz-clare2020]: human listeners' perceptual judgments on two phonetic categories /b/ and /p/ (Figure \@ref(fig:schertzclare)B) can be predicted by considering the phonetic properties of the input *relative to the distribution of phonetic cues* that listeners have previously experienced (Figure \@ref(fig:schertzclare)A). For recent, introductions to distributional thinking about the production-perception link, we refer to @bent-baeseberk2021, @kurumada-roettger2021, @quam-creel2021, and @schertz-clare2020.

\begin{figure}[h]
\begin{center}
\includegraphics[width=.7\columnwidth]{`r get_path("../figures/diagrams/schertzclare.png")`}
\caption{Speech production realizes phonetic categories as distributions in a multi-dimensional acoustic or phonetic cue space. Implicit knowledge of these distributions is known to mediate listeners’ interpretation of speech inputs (reprinted from Schertz and Clare, 2020, permission pending). {\bf Panel A:} voice onset time (VOT) and fundemental frequency (f0) of word-initial stops from 24 English speakers' productions (data from Schertz, 2014). {\bf Panel B:} 24 English listeners' responses to a 2AFC ``ba'' vs. ``pa'' categorization task depending on VOT and f0. Each cell represents one stimulus, with the shading of the cell representing the percentage of ``pa'' response (data from Schertz, Cho, Lotto, and Warner, 2016).}\label{fig:schertzclare}
\end{center}
\end{figure}

We focus on modeling offline responses, which remain one of the most commonly employed measures in research on speech perception. This includes categorization/identification responses in two-forced-choice (2AFC) tasks that continue to be the standard approach to assessing the effects of recent exposure on subsequent speech perception. 2AFC tasks are used in the test phases of experiments on perceptual recalibration [e.g., @norris2003; @kraljic-samuel2006; @vroomen2007; @reinisch-holt2014; @drouin2016; @liu-jaeger2018; @zheng-samuel2020] and distributional learning [e.g., @clayards2008; @maye2008; @munson2011; @kleinschmidt2015], and are also used in experiments on accent adaptation [e.g., @xie2017]. The same general framework we develop here can, however, be extended to offline and online tasks with two or more categorical outcomes, including spoken repetition [e.g., @bieber2021], transcription [e.g., @bradlow-bent2008; @clopper-bradlow2008; @cooper-bradlow2016; @gordonsalant2010], accuracy in cross-modal priming [e.g., @eisner2013; @clarke-garrett2004; @sjerps-mcqueen2010; @xie2018jasa], or fixations in the visual world paradigm [e.g., @hanulikova-weber2012; @nixon2016]. It is also conceptually related to general process models of online perceptual decision-making [e.g., the drift diffusion model, @ratcliff2011]. ^[We also note that here we focus on the recognition of phonetic categories---be it a phoneme, syllable, or word--- *out of context*. We do not aim to model the well-documented effects of phonotactic [e.g., @carlisle1991; @cutler-jesse2021], prosodic [e.g., @munro1995; @sereno2015], lexical/semantic [e.g., @cooper-bradlow2016; @davis2005], visual [e.g., @bertelson2003; @ganong1980; @vroomen2007; @vroomen-baart2009] and sentential/discourse context [e.g., @contemori-tortajada2020; @klatt1975; @holt-bent2017; @winn2018]. The results we present below generalize to situations in which such context is taken into account (in the formulation of our model, context simply changes the overall response bias). Critically, some models of spoken word recognition have been shown to capture contextual effects [DIANA, @bosch2015; NAM, @luce-pisoni1998; TRACE, @mcclelland-elman1986; EARSHOT, @magnuson2020], and these models share the general assumptions we make here.]<!--CK: this part was moved to a footnote just because it has a lot of refs and it detracts from the flow. But we can put this back in if we think this is critical-->

For the present purpose, we can think of the the mapping from acoustic inputs to categorization responses as involving three sets of processes illustrated in Figure \@ref(fig:model-perceptual-decision-making). 
<!-- ^[By presenting these processes as three different steps, we do not mean to imply that they are discrete, information encapsulated processes. We merely aim for a conceptually transparent description of some of the core components of speech perception that could be affected by recent exposure. The framework we present is overly simplistic in many ways. For example, neural noise and signal transformations could affect any of the three steps, not just the first one.]  -->
We first describe these three mechanistic levels along with the parameters they introduce ($\lambda$, $\pi$s, $\mu_c$s, $\Sigma_c$s, and $\mu$ in Figure \@ref(fig:model-perceptual-decision-making)). Then we introduce the linking hypotheses that describe how the parameters that characterize each mechanism can change with exposure. 


<!-- This is the code to generate the graphical model:
\begin{figure}
  \centering
  \tikz{ % 
  -->
  
<!-- response -->
    
<!--\node[obs] (r) {$r$} ; %
    \node[const, left=of r, xshift=-.5cm] (response) {{\bf response}} ; %
  -->
  
<!-- decision-making -->
    
<!--
    \node[det, below=of r] (decision) {} ; %
    \factor[below=of decision] {response-dist} {left: $\mathcal{M}$} {} {}; %
    \node[const, left=of decision, xshift=-.5cm] (decision-rule) {{\bf decision rule}} ; %
    \node[latent, right=of response-dist, xshift=1.1cm] (l) {$\lambda$} ; %
    \node[const, right=of l] (lapse) {{\em lapse rate} ($1$ DF)} ; %
    \edge {decision} {r} ; %
    \edge {response-dist} {decision} ; %
    \edge {l} {response-dist} ; %
  -->
  
<!-- likelihood -->

<!--
    \factor[below=of response-dist, yshift=-1.25cm] {posterior-dist} {left: Multi} {} {}; %
    \node[const, left=of posterior-dist, xshift=-.5cm] (posterior) {{\bf category posterior}} ; %
    \factor[below=of posterior-dist, yshift=-1cm] {likelihood-dist} {left: $\mathcal{N}$} {} {}; %
    \node[const, left=of likelihood-dist, xshift=-.5cm] (posterior) {{\bf category likelihood}} ; %
    \node[latent, right=of likelihood-dist, yshift=0.5cm] (mu-c) {$\mu_c$} ; %
    \node[latent, right=of likelihood-dist, yshift=-0.5cm] (sigma-c) {$\Sigma_c$} ; %
    \node[const, right=of mu-c] (mu-c-label) {{\em category means} ($JK$ DF)} ; %
    \node[const, right=of sigma-c] (sigma-c-df) {{\em category covariance matrices} (up to $\frac{J}{2}(K^2+K)$ DF)} ; %
    \edge {posterior-dist} {response-dist} ; %
    \edge {likelihood-dist} {posterior-dist} ; %
    \edge {mu-c} {likelihood-dist} ; %
    \edge {sigma-c} {likelihood-dist} ; %
 -->

<!-- prior -->

<!--
    \factor[right=of response-dist, xshift=.5cm, yshift=-1cm] {prior-dist} {left: Multi} {} {}; %
    \node[latent, right=of prior-dist] (b) {$\pi$} ; %
    \node[const, right=of b] (prior) {{\em response biases} ($J-1$ DF)} ; %
    \edge {prior-dist} {response-dist} ; %
    \edge {prior-dist} {posterior-dist} ; %
    \edge {b} {prior-dist} ; %
-->

<!-- normalization -->

<!--
    \node[det, below=of likelihood-dist, yshift=-0.4cm] (xprime) {} ; %
    \node[const, left=of xprime, xshift=-.5cm] (normalization) {{\bf normalization}} ; %
    \node[latent, right=of xprime, xshift=.9cm] (mu) {$\mu$} ; %
    \node[const, right=of mu] (mu-label) {{\em cue mean} ($K$ DF)} ; %
    \edge {xprime} {likelihood-dist} ; %
    \edge {mu} {xprime} ; %
-->   

<!-- acoustic input -->

<!--
    \node[obs, below=of xprime] (x) {x} ; %   
    \node[const, left=of x, xshift=-.5cm] (acoustic) {{\bf acoustic input}} ; %   
    \edge {x} {xprime} ; %
  }
-->

\begin{figure}[h]
\begin{center}
\includegraphics[width=.9\columnwidth]{`r get_path("../figures/diagrams/graphical-model.png")`}
  \caption{A simplified general {\em categorization model} for $J$-AFC alternative-choice tasks (e.g., vowel categorization, word transcription, etc.) over a $K$-dimensional phonetic input. Filled gray circles represent variables the researcher can observe. Empty circles represent latent variables that are not observable. Diamonds represent variable-free processes. Only variables that we consider as being potentially affected by recent exposure are shown (see text for additional detail). Parentheses describe the number of degrees of freedom (DF) introduced by each parameter. In practice, many of these DFs can be fixed based on data from a phonetic database and/or previous perception experiments (see text for details). Squares are annotated with the distributions resulting at that level of the model: $\mathcal{N}$(ormal), Multi(nomial), and $\mathcal{M}$(ixture) distributions. For 2AFC tasks, all multinomial distributions simplify to Bin(omial) distributions.} \label{fig:model-perceptual-decision-making}
\end{center}
\end{figure}

## 'Pre-linguistic' processes: signal transformations and normalization
The first step in our categorization model maps the acoustic input onto *perceptual* features. These perceptual features are the outcome of low-level signal transformations and normalization processes.^[The term normalization is often used to refer to both of these components together. For example, some of the most common normalization approaches involve both log-transforms and further normalization steps [e.g., Lobanov normalization, @lobanov1971; height-backness normalization, @miller1989]. Transformation and normalization can, however, be understood as separate processes [see also "vowel-intrinsic" vs. "vowel-extrinsic" procedures in @adank2004].] Experiments on the perception of stimulus similarity suggest, for example, that the human brain represents frequency information logarithmically [@greenwood1961]. This is captured by, for example, the Mel [@stevens1937], Bark [@zwicker1961], and ERB [@moore-glasberg1983] transformations. Such logarithm-transformed spectral cues have been found to provide a better fit against human categorization responses than features based on raw frequencies [@hoffmanbion-escudero2007; @kleinschmidt2019; @richter2017]. The case studies we present below model perception for a phonological contrast that depends on both temporal and spectral cues. For the spectral cue, we use Mel-transformed frequencies.<!-- Put differently, the perceptual feature relevant to vowel categorization seem to be log-transformed, rather than raw, frequencies. Here, the purpose of our simplified model is to make predictions about the differences in effects resulting from exposure to different acoustic inputs. The specific nature of the perceptual features relevant to any given categorization problem (e.g., vowel categorization) is thus not of relevance for the present purpose. -->

*Normalization* refers to further transformation of acoustic inputs based on either other acoustic properties or the overall distribution of the acoustic input itself [for a review, see @weatherholtz-jaeger2016]. For example, one of the most influential normalization procedures for the formant cues that affect vowel perception centers and standardizes these cues based on the talker-specific mean and standard deviation of the formant values [@lobanov1971]. This and conceptually similar normalizations [e.g., @gerstman1968] have been found to remove a substantial amount of cross-talker variability in the realization in vowels while maintaining phonemic contrasts and sociolinguistic information [@adank2004], providing a good fit against vowel categorization by human listeners [@hoffmanbion-escudero2007]. Because normalization operates prior to linguistic representations, it potentially provides a particularly efficient way to remove uninformative variability---e.g., by taking advantage of *all* available information about a cue, not just the observations of a specific set of categories [@apfelbaum-mcmurray2015].

The case studies we present below employ a general model of normalization that can be applied to any type of phonological contrast [C-CuRE, @cole2010; @mcmurray-jongman2011]. C-Cure stands for "computing cues relative to expectations" and simply centers cues by subtracting the (expected) mean for that cue in the current context ($\mu$ in Figure \@ref(fig:model-perceptual-decision-making)). C-CuRE has been found effective in accounting for cross-talker differences as well as effects of surrounding phonological context, improving the ability to predict human responses compared to a model without any normalization [@mcmurray-jongman2011; see also @apfelbaum-mcmurray2015; @kleinschmidt2020; @mcmurray-jongman2016; @xie2021cognition]. <!-- For f0, C-CuRE normalization over Mel-transformed frequencies is closely related to semi-tones, a transformation that is commonly employed for spectral cues [@REF].--> 
Figure \@ref(fig:demonstrate-normalization) visualizes the effects of C-CuRE normalization on the marginal distributions of f0 and VOT to word-initial stop voicing in American English (e.g., /b/ vs. /p/ in *bin* vs. *pin*). The specific procedure is described in the SI (\@ref(sec:SI-chodroff)). We use these data throughout the remainder of this study, including the two case studies.

(ref:demonstrate-normalization) Effects of applying C-CuRE normalization to productions of word-initial stop voicing in American English (e.g., *bin* vs. *pin*). The data come from @chodroff-wilson2018. **Panel A:** unnormalized VOT and f0. VOT is the primary cue to this voicing contrast for American English, and f0 is known to be a secondary cue. The data exhibit clear evidence of multimodality along both VOT and f0. **Panel B:** the same productions but after C-CuRE normalization has been applied to remove talker-specific variability. Compared to unnormalized data, the C-CuRE normalized data exhibits reduced variability and reduced evidence of multimodality (the low-f0 outliers are the result of creaky voice and pitch-halving, see SI \@ref(sec:SI-chodroff)). 

```{r demonstrate-normalization, fig.width= base.width * 3, fig.height = base.height * 2 + 2, fig.cap="(ref:demonstrate-normalization)"}
p <- d.chodroff_wilson %>% 
  ggplot(aes(x = VOT, y = f0_Mel, color = voicing)) +
  scale_x_continuous(expression("VOT (ms)")) +
  scale_y_continuous(expression("f0 (Mel)")) +
  scale_color_manual("Voiced", breaks = c("yes", "no"), values = colors.voicing) +
  facet_grid(. ~ poa) + 
  guides(colour = guide_legend(override.aes = list(alpha = 1)), shape = guide_legend(override.aes = list(alpha = 1))) + 
  theme(legend.position = "top")

p1 <- 
  p + 
  geom_point(
    mapping = aes(shape = gender),
    alpha = .05) +
  scale_shape_discrete("Gender") 

limits <- get_plot_limits(p1)
p2 <-   
  p1 + theme(legend.position = "none", plot.margin = margin(t = -50)) +
  aes(x = VOT_centered, y = f0_Mel_centered) +
  coord_cartesian(xlim = c(limits$xmin, limits$xmax), ylim = c(limits$ymin, limits$ymax))

plot_grid(
  plotlist = list(p1, p2), 
  nrow = 2, labels = c("A)", "B)"),
  align = "h",
  axis = "lrtb")
```

Beyond signal transformations and normalization, the stimulus observed by a listener is also affected by perceptual noise (not shown in Figure \@ref(fig:demonstrate-normalization)). This means that even the same exact acoustic stimulus does not necessarily result in the same percept [@feldman2009]. The integration of noise into models of speech perception has been shown to explain otherwise puzzling differences in the perception and recognition of different types of phonological contrasts [e.g., @kronrod2016]. Although not critical for the present purpose, we incorporate perceptual noise into our model also because it results in more human-like (less steep) categorization functions. This noise is held constant across all case studies presented below, set to the values obtained by Kronrod and colleagues [-@kronrod2016, $\sigma^2_{noise, VOT}=80 msec^2$, $\sigma^2_{noise, spectral}=878 Mel^2$].

## Linguistic representations: from perceptual features to linguistic categories {#sec:representations}
The output of normalization is the input to the mapping onto linguistic categories. All major theories of speech perception agree that this involves implicit knowledge of the distributional realization of linguistic categories---i.e., the distribution of acoustic or phonetic cues that are observed across instances of the category. In analytic models, this mapping is typically described by the *category likelihood* that is learned from previous inputs and applied to subsequent input using Bayes theorem [e.g., in the neighborhood activation model, @luce-pisoni1998; shortlist B, @norris-mcqueen2008; and other Bayesian inference models, @clayards2008; @feldman2009; @kleinschmidt-jaeger2015]. In exemplar models and related theories, the same mapping is achieved by storing previously experienced inputs as exemplars [e.g., @johnson2006; @pierrehumbert2001; @wedel2006] or episodic traces [@goldinger1996] that subsequent inputs are compared to during recognition (e.g., by means of $k$-nearest neighbor algorithms, @fix-hodges1989). In connectionist and deep neural network models, the same probabilistic mapping is achieved through latent structure in the network that is learned from previous input [@mcclelland-elman1986; @magnuson2020]. Although the specific nature of these representations continues to be a matter of debate, all of these theories share the assumption that there is a probabilistic mapping between perceptual cues and linguistic categories [see also @shi2010 on the close computational relation between exemplar and Bayesian inference models].

Here we employ an analytic characterization of category likelihoods. Specifically, we adopt a simplifying assumption commonly made in research on speech perception [@clayards2008; @feldman2009; @kleinschmidt-jaeger2015; @norris-mcqueen2008] and automatic speech recognition [@jurafsky-martin2000] that the cue distributions for each category follow a multivariate Gaussian distribution. In Figure \@ref(fig:model-perceptual-decision-making), this is indicated through the two parameters that are sufficient to specify each multivariate Gaussian (the category means $\mu_c$ and the category covariance matrices $\Sigma_c$).^[This assumption strikes a compromise between two common alternatives. A representationally less complex proposal introduces an independence assumption and describes linguistic categories through *independent uni*variate Gaussians for each cue dimension. The likelihoods from the univariate Gaussians is then combined through a cue integration model. This substantially reduces the required degrees of freedom---both for learners/listeners and the researcher [see @toscano-mcmurray2010]. A representationally more complex alternative dispenses of the Gaussian assumption and instead assumes that listeners store all previously experienced exemplars [or some pruned set of exemplars, @pierrehumbert2001]. This allows for more accurate (non-parametric) representations of previous experience but also introduces many additional degrees of freedom--both for learners/listeners and the researcher [for discussion, see @apfelbaum-mcmurray2015]. For the present purpose, we do not see how these alternatives would change the conclusions we draw below.] Bivariate Gaussian categories fit to the data from @chodroff-wilson2018 are shown in Figure \@ref(fig:show-representations-plots), along with the categorization functions of the f0-VOT space that would result from these categories prior to considering other effects on decision-making that we discuss in the next section.

(ref:show-representations-plots) Illustrating listeners' implicit category representations. **Top row:** Bivariate Gaussian category likelihoods learned from (fit to) the by-talker normalized cue distributions in Figure \@ref(fig:demonstrate-normalization)B. Ellipses show 95% probability mass. **Bottom row:** Categorization functions that would result from these category likelihoods prior to taking into account other effects on decision making (see Figure \@ref(fig:show-lapse-bias-demonstration-plots) in the next section).

```{r demonstrate-representations, warning=FALSE}
# Set lapse rate and response bias
lambda = 0
pi = .5

# Set parameters
limits <- get_plot_limits(p2)
VOT_range = c(0, limits$xmax)
f0_range = c(limits$ymin, limits$ymax)
n_points = 100
cue_names = c("VOT", "f0")

# Set margins for the 3D plots
margin <- list(
  l = 0,
  r = 0,
  b = 0,
  t = 0,
  pad = 0 # space between the plotting area and the axis lines; takes a number >=0
)

for(j in 1:length(levels(factor(d.chodroff_wilson$poa)))){
  category.contrasts <- unlist(strsplit(levels(factor(d.chodroff_wilson$poa))[j], "-"))
  
  model <- 
    make_MVG_from_data(data = d.chodroff_wilson, cues = c("VOT_centered", "f0_Mel_centered")) %>%
    filter(category %in% category.contrasts)
  
  output <- demonstrate_representations_3D(model, n_points, VOT_range, f0_range, cue_names, lambda, pi)
  
  
  # Set image size
  p_width = 700
  p_height = 700
  p.3d.density <- plot_3D.density(output$d.bivn, output$t.bivn, output$d.ellipse, output$t.ellipse, output$color) %>% layout(margin = margin)
  
  # Set image size
  p_width = 900
  p_height = 900
  p.3d.categorization <- plot_3D.categorization(output$df.resp)
  
  save_figure_or_not(p.3d.density, paste0('p.3d.density.panel_', j,'.png'))
  save_figure_or_not(p.3d.categorization, paste0('p.3d.categorization.panel_', j,'.png'))
}
```

```{r show-representations-plots, fig.ncol = 3, fig.show='hold', fig.align='center', out.width="33%", out.height="49%", fig.cap="(ref:show-representations-plots)", fig.subcap=c('Distributions for /b/ and /p/', 'Distributions for /d/ and /t/', 'Distributions for /g/ and /k/', 'Categorization for /b/-/p/', 'Categorization for /d/-/t/', 'Categorization for /g/-/k/')}
filename = c()
for (j in 1:length(levels(factor(d.chodroff_wilson$poa)))) {
  filename[j] = file.path(get_path('../figures/plotly/'), paste0('p.3d.density.panel_', j,'.png'))
}

for (j in 1: length(levels(factor(d.chodroff_wilson$poa)))) {
  filename[j + 3] = file.path(get_path('../figures/plotly/'), paste0('p.3d.categorization.panel_', j,'.png'))
}

knitr::include_graphics(filename)
```


## 'Post-linguistic' decision-making: incorporating priors, response biases, and attentional lapses
The third and final step in our simplified model takes the output of the second step and derives a decision/recognition.^[In some contexts, it can be productive to further split this step into *recognition* of the category and post-recognition processes that affect the behavioral *response*. For the present purpose, we group these processes together. Similarly, some models of perceptual decision-making distinguish between *decision thresholds* (the amount of evidence necessary before a decision is being made) and *decision biases* [stimulus-independent effects on the activation or probability of a response option, @clarkedavidson2008; @venezia2012]. For the present purpose, these two have essentially identical effects.] This includes the integration of information about the prior probability of a category in the current context, $p(c | context)$. In Bayesian ideal observer models, this integration takes place according to Bayes theorem, yielding an estimate of each category's posterior probability [e.g., @luce-pisoni1998; @norris-mcqueen2008]. Alternative computational approaches can introduce additional degrees of freedom, for example, by allowing non-optimal weighting of priors and category likelihoods. As our goal here is to arrive at as simple a model as possible, we follow the approach taken in ideal observers:

\begin{equation}\label{eq:posterior-probability}
\begin{split}
p(category | input) & = \frac{p(input | c) p(c)}{\Sigma_i p(input | c_i) p(c_i)} \\
                    & = \frac{\mathcal{N}\!(input | \mu_c, \Sigma_c) p(c)}{\Sigma_i \mathcal{N}\!(input | \mu_{c_i}, \Sigma_{c_i}) p(c_i)}
\end{split}
\end{equation}

<!-- Could include context explicitly but that then requires additional explanation: p(category | input, context) = \frac{p(input | c, context) p(c | context)}{\Sigma_i p(input | c_i, context) p(c_i | context)}

Of this model is further simplified by making the independence assumption that the likelihood of the category $c$ does not depend on the context. While this assumption is not always warranted, it is trivially true for the case studies we present below, none of which takes context into account ... -->
  
where the second row substitutes the Gaussian category likelihoods assumed in the previous section into the equation. In Bayesian models, $p(c_i)$ is generally assumed to reflect a rational estimate based on either the relative frequency of the category in this type of context in listeners' longterm experience or an estimate based on the expectations about the present context. The latter allows for the integration of *response biases* that go beyond capturing the relative frequency of categories in previous experience. In an experiment with a 2AFC task, for example, participants might expect both response options to occur about equally often. This might lead participants to adjust response biases based on the sequence of most recently observed categories. The simplified model in Figure \@ref(fig:model-perceptual-decision-making) captures these response biases---regardless of whether they reflect priors based on the relative frequency of categories, meta-reasoning about the structure of experiments, or other factors---through the parameter $\pi$. 
For a $J$-way categorical outcome, this introduces $J-1$ degrees of freedom (since $\Sigma_i \pi_{c_i} = 1$) that cannot be independently estimated from phonetically annotated databases. These parameters can, however, often be set based on assumptions about the current task as well as on the extent to which prior expectations about natural language transfer to this task. For example, standard experimental designs provide participants with ample evidence that prior expectations based on the relative frequency of lexical items in natural language use do *not* transfer to the experiment [cf. @jaeger2010]. In such contexts, participants might quickly come to adjust their expectations and employ uniform response biases.

In addition to response biases, the model in Figure \@ref(fig:model-perceptual-decision-making) includes the possibility that listeners sometimes respond *in*dependent of the stimulus. Stimulus-independent responses can occur, for example, because of attentional lapses. On such occasions, the response is only influenced by the response biases. Lapsing models *without* consideration of responses biases have previously been used in some analyses of exposure effect on speech perception [@clayards2008; @mcmurray-jongman2011; @kleinschmidt-jaeger2016cogsci]. In our model, we further assume that these response biases on lapsing trials are identical to the responses biases on non-lapsing trials. This yields the following simplified model of the joint effect of attentional lapses and responses biases, where $\lambda$ is lapse rate---the probability of lapsing:^[Readers familiar with psychometric models might recognize the close relation between Equation \@ref(eq:posterior-probability-lapse) and the standard psychometric model in @wichmann-hill2001: $\gamma + (1-\gamma-\lambda) F(stimulus | \alpha, \beta)$. In the Wichmann and Hill model, $\gamma$ describes the floor and $1-\lambda$ describes the ceiling probability. In Equation \@ref(eq:posterior-probability-lapse), $\lambda$ is the lapse rate and $\pi$ determines how the lapses (and non-lapses) are affected by response biases, resulting in a floor of $\lambda \pi$ and a ceiling of $1 - \lambda(1 - \pi)$. For the special case of two Gaussian categories with identical variance along a unidimensional cue continuum, Equation \@ref(eq:posterior-probability-lapse) can be described by Wichmann and Hill's psychometric model if the perceptual model $F$ is set to be a logistic with appropriate choice of its threshold $\alpha$ and slope $\beta$ [cf. @kleinschmidt-jaeger2015, 200].]  

\begin{equation}\label{eq:posterior-probability-lapse}
p(category | input) = (1 - \lambda) \frac{\mathcal{N}\!\left( input | \mu_c, \Sigma_c \right) \pi}{\Sigma_i \mathcal{N}\!\left( input | \mu_{c_i}, \Sigma_{c_i} \right) \pi_i} + \lambda \frac{\pi}{\Sigma_i \pi_i}
\end{equation}

In Figure \@ref(fig:model-perceptual-decision-making), the fact that response bias affect listeners' responses in both lapsing and non-lapsing trials is indicated by the two arrows leaving from $\pi$. Figure \@ref(fig:show-lapse-bias-demonstration-plots) visualizes the effects of the two parameters $\lambda$ and $\pi$. 

(ref:show-lapse-bias-demonstration-plots) Illustrating the effects of $\lambda$ and $\pi$ on the posterior probability of /d/, using the two bivariate Gaussian categories of /d/ and /t/ shown in Figure \@ref(fig:show-representations-plots)b. The colored planes indicate the ceiling and flooring levels of posterior probability of /d/. Panel a) here is identical to Panel e) in Figure \@ref(fig:show-representations-plots)，with $\lambda$ = 0 and $\pi_{/d/}=.5$. **Top panel:** Differences in lapse rate $\lambda$ for a uniform bias of $\pi_{/d/}=.5$. As the lapse rate increases, the ceiling and flooring responses at the end points change while the categorization slope remains the same. **Bottom panel:** Differences in bias $\pi_{/d/}$ when the lapse rate $\lambda$ = .2. As the bias towards /d/ changes from 0.1 to 0.9, the categorization surface shifts upwards and to the right, resulting in more /d/ responses across the phonetic space.

```{r lapse-bias-demonstration-3D, warning = FALSE}
# Set image size
p_width = 900
p_height = 900
  
lambda = c(0, .2)
pi = c(.1, .9)
category.contrasts = c("/d/", "/t/")

for(p in 1:length(lambda)){
  model <- 
    make_MVG_from_data(data = d.chodroff_wilson, cues = c("VOT_centered", "f0_Mel_centered")) %>%
    filter(category %in% category.contrasts)
  
  output <- demonstrate_representations_3D(model, n_points, VOT_range, f0_range, cue_names, lambda[p], .5)
  
  p.3d.categorization <- plot_3D.categorization(output$df.resp) %>%
    add_surface(
      z = matrix(rep(max(output[["df.resp"]][["d_prop"]]), 10000), ncol=100),
      opacity = 0.1, color = "gray") %>% # add ceiling plane
    add_surface(
      z = matrix(rep(min(output[["df.resp"]][["d_prop"]]), 10000), ncol=100),
      opacity = 0.1, color = "gray") %>% # add flooring plane
    layout(
      margin = margin,
      scene = list(
        camera = list(
          eye = list(x = -0.5, y = -2.5, z = 0.1)))) # perspective good for showing categorization curve
  
  save_figure_or_not(p.3d.categorization, paste0('p.3d.categorization.panel_lambda=', p,'.png'))
}

for(p in 1:length(pi)){
  model <- 
    make_MVG_from_data(data = d.chodroff_wilson, cues = c("VOT_centered", "f0_Mel_centered")) %>%
    filter(category %in% c("/d/", "/t/"))
  
  output <- demonstrate_representations_3D(model, n_points, VOT_range, f0_range, cue_names, .2, pi[p])
  
  p.3d.categorization <- plot_3D.categorization(output$df.resp) %>%
    add_surface(
      z = matrix(rep(max(output[["df.resp"]][["d_prop"]]), 10000), ncol=100),
      opacity = 0.1, color = "gray") %>% # add ceiling plane
    add_surface(
      z = matrix(rep(min(output[["df.resp"]][["d_prop"]]), 10000), ncol=100),
      opacity = 0.1, color = "gray") %>% # add flooring plane
    layout(
      margin = margin,
      scene = list(
        camera = list(
          eye = list(x = -0.5, y = -2.5, z = 0.1)))) # perspective good for showing categorization curve
  
  save_figure_or_not(p.3d.categorization, paste0('p.3d.categorization.panel_pi=', p,'.png'))
}
```

```{r show-lapse-bias-demonstration-plots, fig.ncol = 2, out.width="49%", out.height="49%", fig.show='hold',fig.align='center', fig.cap="(ref:show-lapse-bias-demonstration-plots)", fig.subcap=c('$\\lambda$ = 0, $\\pi_{/d/}=.5$', '$\\lambda$ = .2, , $\\pi_{/d/}=.5$', '$\\lambda$ = .2, $\\pi_{/d/}=.1$', '$\\lambda$ = .2, $\\pi_{/d/}=.9$') }
filename = c()
for (p in 1:length(lambda)) {
  filename[p] = file.path(get_path('../figures/plotly/'), paste0('p.3d.categorization.panel_lambda=',p,'.png'))
}

for (p in 1: length(pi)) {
  filename[p + length(lambda)] = file.path(get_path('../figures/plotly/'), paste0('p.3d.categorization.panel_pi=',p,'.png'))
}

knitr::include_graphics(filename)
```

The final part of the model is the decision rule that takes the posterior in Equation \@ref(eq:posterior-probability-lapse) as input and returns a response. Here, we follow a common assumption in research in speech perception and employ Luce's choice rule [@luce1959; for a comparison of decision rules, see @massaro-friedman1990]. Under this decision rule, the predicted distribution of responses is identical to the posterior in Equation \@ref(eq:posterior-probability-lapse). For example, in a 2AFC categorization task, a posterior probability of .3 for /d/ and .7 for /t/ would result in a /d/-response with .3 probability or a /t/-response with .7 probability. 

This completes the description of the categorization model in Figure \@ref(fig:model-perceptual-decision-making). For any parameterization of $\lambda$, $\pi$, $\mu_c$, $\Sigma_c$, and $\mu$, this model takes acoustic stimuli as input and returns predictions about the expected response distribution (e.g., 30% /d/-responses and 70% /t/-responses). Next, we extend this model to capture *changes* at any of the three mechanistic levels. That is, we specify linking hypotheses that describe how the values of $\pi$, $\mu_c$, $\Sigma_c$, and $\mu$ can change with exposure. Once these linking hypotheses are specified, the model can be used to derive predictions for the distribution of human responses following exposure---for example, during the test phase of an experiment on perceptual recalibration or accent adaptation (see Figure \@ref(fig:overview-change)).

## Modeling *changes* in normalization {#sec:change-normalization}

```{r}
set.seed(5612)

categories.demo <- c("/d/", "/t/")
cue.demo <- "VOT_centered"

# Priors
weak <- 4
strong <- 1024

# Lapse model
lambdas.demo <- c(0, .05)
bias.demo <- c(.5, .5)

# Ideal observers and adaptors
m.io.VOT <- 
  make_MVG_from_data(
  data = d.chodroff_wilson,
  category = "category",
  cues = cue.demo) %>%
  filter(category %in% categories.demo) %>%
  lift_MVG_to_MVG_ideal_observer(prior = bias.demo, lapse_rate = 0, lapse_bias = bias.demo, Sigma_noise = matrix(80, nrow = 1))

m.ia.VOT <-
  crossing(
    prior_kappa = c(weak, strong),
    prior_nu = c(weak, strong),
    lambda = lambdas.demo) %>%
  mutate(
    posterior = map2(
      prior_kappa, 
      prior_nu, 
      ~ lift_MVG_ideal_observer_to_NIW_ideal_adaptor(model = m.io.VOT, kappa = .x, nu = .y))) %>%
  unnest(posterior)  %>%
  mutate(lapse_rate = lambda)

# Make artificial VOT data set in which category means are shifted downwards
category_shift.demo <- 25
n.demo <- 20

d.exposure.demo <- 
  make_MVG_data(
    Ns = rep(n.demo, 2), 
    mus = c(m.io.VOT$mu[[1]] + category_shift.demo, m.io.VOT$mu[[2]] + category_shift.demo), 
    Sigmas = map2(m.io.VOT$Sigma, list(1, 2), ~ .x / .y), 
    randomize.order = T) %>%
      rename(!! sym(cue.demo) := cue1) %>%
      mutate(category = ifelse(category == 1, "/d/", "/t/")) %>%
  nest(data = everything()) 

# Visualization
VOT_range <- c(0, 110)
VOT_resolution = 100
```

Like many other models of normalization, previous implementations of C-CuRE assumed that the theoretical quantities employed in normalization---for C-CuRE, the means of all cues---are *known* to the listeners [e.g., @apfelbaum-mcmurray2015; @mcmurray-jongman2011]. However, listeners must somehow *infer* these quantities from the observed inputs [see also Section 3.3 in @weatherholtz-jaeger2016]. For example, in the types of experiments we consider below, listeners need to *infer* the unfamiliar talker's cue means from the inputs observed during exposure. At the beginning of exposure, the best estimates of the cue means for the unfamiliar talker are the mean expected based on listeners' longterm experience with various different talkers ($\mu_0$). With increasing exposure to the unfamiliar talker, listeners can update their estimates of the talker's cue means based on the input. We thus need to expand C-CuRE with a linking hypothesis that describes how listeners update their estimates of the unknown mean---not unlike representational accounts, but only for the *overall* (marginal) distribution of cues, rather than for each category. 

Some proposals for such functions include moving-window algorithms that estimate the mean as the sample mean over a finite number of the most recent observations [@lee2002; @zhang-peng2021]. Here, we model listeners' estimate of the talker-specific cue mean $\mu_n$ after $n$ observations from that talker as simple linear interpolation between the cue mean observed in previous longterm experience ($\mu_0$) and the mean observed in the sample observed from the unfamiliar talker ($\bar{x}$). This approach has the advantage that listeners can draw on prior experience when they do not yet have much (or any) data from an unfamiliar talker. They can then update the inferred cue mean as they observe further data from the talker [see discussion of the flexibility-stability trade-off in @kleinschmidt-jaeger2015, p. 178-182]:

\begin{equation}\label{eq:normalization-change}
\mu_n = \frac{1}{\kappa_0 + N} \left( \kappa_0 \mu_0 + N \bar{x} \right) = \frac{\kappa_0}{\kappa_0 + N} \mu_0 + \frac{N}{\kappa_0 + N}\bar{x} 
\end{equation}

The two parameters describing the input from the unfamiliar talker, $n$ and $\bar{x}$, are determined by the exposure data used in the experiment (the estimation of the cue means, $\bar{x}$ requires that the exposure stimuli are phonetically annotated). $\mu_0$ can be estimated from sufficiently large phonetically annotated databases of speech, essentially assuming that listeners have learned the overall cue means across talkers from previously experienced speech input. This is what we did to create Figure \@ref(fig:demonstrate-normalization), and it is what we assume in the remainder of this study. This leaves only one degree of freedom that is not independently determined: the relative weight of previous experience compared to the input received from the talker so far ($\kappa_0$). This is the parameter we vary in the case studies presented below to illustrate the types of results that can be explained through changes in normalization due to recent exposure.

<!--- COULD ADD GRAPHICAL MODEL HERE THAT SHOWS THIS ESTIMATION FROM THE RESEARCHER'S PERSPECTIVE: ALL BUT KAPPA_0 WOULD BE FILLED CIRCLES. -->

## Modeling *changes* in linguistic representations {#sec:ideal-adaptor}
Just like listeners need to infer an unfamiliar talker's overall cue mean for normalization, listeners who learn talker-specific representations need to infer the *category* means and covariance matrices of the unfamiliar talker. That is, changes in representations can be described as the process of inferring the talker's category likelihood. A theory of this inference process---the ideal adaptor---is introduced in @kleinschmidt-jaeger2015. Bayesian belief-updating models based on this theory have been shown to provide a good qualitative and quantitative fit against human responses in results of experiments on perceptual recalibration [@kleinschmidt-jaeger2011; @kleinschmidt-jaeger2012; for closely related models, see @xie2021cognition], unsupervised or semi-supervised distributional learning [e.g., @kim2020; @kleinschmidt-jaeger2016pbr; @theodore-monto2019; for closely related model, see @bejjanki2011; @clayards2008], and accent adapation [@hitczenko-feldman2016; for a closely related model, see @tan2021]. However, as outlined in the introduction, an explicit comparison with alternative models that change normalization or responses biases has been lacking.

The belief-updating model describes the inference of category means and category variances in ways that are conceptually similar to the type of interpolation we described in Equation \@ref(eq:normalization-change), by combining knowledge based on previously experienced speech input with the observations made from the unfamiliar talker. The specific instance of the model we use here---belief-updating over a Normal-Inverse-Wishart ($\mathcal{NW^{-1}}$) prior [@kleinschmidt-jaeger2015]---describes the uncertainty listeners have about the category means $\mu_c$ and category covariance matrices $\Sigma_c$ prior to any observations from an unfamiliar talker as a function of four variables [@murphy2012, p. 132-3]:
  
\begin{equation}\label{eq:niw-updating}
\begin{split}
p\left( \mu_c, \Sigma_c | \mathcal{D} \right) & = \mathcal{NW}^{-1} \left( \mu_c, \Sigma_c | \mathrm{m}_{c,0}, \kappa_{c,0}, \nu_{c,0}, \mathrm{S}_{c,0} \right) \\
& = \mathcal{N}\left( \mu_c | \mathrm{m}_{c,0}, \frac{1}{\kappa_{c,0}} \Sigma_{c} \right) \times \mathcal{W}^{-1}\left( \Sigma_c | \mathrm{S}_{c,0}, \nu_{c,0} \right)
\end{split}
\end{equation}

The Normal part of the $\mathcal{NW^{-1}}$ model describes the uncertainty about the category mean $\mu_c$, the Inverse-Wishart part describes the uncertainty about the category covariance $\Sigma_c$. For the former, $\mathrm{m}_{c,0}$ is the mean of the normal distribution describing the uncertainty about the category mean $\mu_c$ and $\kappa_{c,0}$ indicates the extent to which listeners transfer their prior beliefs about the category mean to the present input. The larger $\kappa_{c,0}$ is, the more certain listeners are about the category mean even prior to any observation, and the less their inferences about the talker's category mean will be influenced by observations from the talker. Put differently, larger $\kappa_{c,0}$ predicts slower learning of changes in the category mean. Similarly, $\mathrm{S}_{c,0}$ is the scale matrix of the Inverse-Wishart---having a conceptually similar function to the mean $\mathrm{m}_{c,0}$ of the Normal distribution---and $\nu_{c,0}$ indicates extent to which listeners transfer the prior beliefs about the category covariance to the present input. Just as larger $\kappa_{c,0}$ predicts slower learning of changes in the category mean, larger $\nu_{c,0}$ predicts slower learning of changes in the category covariances. 

In practice, researchers can estimate the $\mathrm{m}_{c,0}$s and the $\mathrm{S}_{c,0}$s such that they yield the category means and covariances that would be expected given listeners' previous long-term experience.^[That is, $\mathrm{m_{0,c}} = \mathbf{E}(\mu_c)$ and  $\mathrm{S_{0,c}} = \mathbf{E}(\Sigma)(\nu_{0,c}-D-1)$, where $D$ is the dimensionality of input (here 1). For details, see Murphy (2012, p.134-5). Additional matching of higher statistical moments should further improve the model.] This leaves two degrees of freedom to model changes in each category's likelihood, $\kappa_{c,0}$ and $\nu_{c,0}$. We further follow previous work to make the simplifying assumption that all categories have the same prior $\kappa_{c,0}$ and $\nu_{c,0}$ [@kleinschmidt-jaeger2015; @kleinschmidt-jaeger2016cogsci], leaving just two degrees of freedom *across* all categories to model changes in representations. These are the two parameters we vary in the case studies presented below to illustrate the types of results that can be explained through changes in representations. Figure \@ref(fig:demonstrate-niw-prior-mu-sigma) demonstrates how $\kappa_{c,0}$ and $\nu_{c,0}$ affect the uncertainty about the category likelihoods for the simple case of univariate Gaussian categories along a single cue dimension (VOT). The case studies we present below employ bivariate categories along f0 and VOT.

(ref:demonstrate-niw-prior-mu-sigma)  Illustrating the effects of $\kappa_{c,0}$ and $\nu_{c,0}$ on the uncertainty about the category means $\mu_c$ and variances $\Sigma_c$ for univariate /d/ and /t/ categories along VOT. The four priors have identical expected category means ($\mathbf{E}(\mu_{/d/}), \mathbf{E}(\mu_{/t/})$) and variances ($\mathbf{E}(\sigma_{/d/}), \mathbf{E}(\sigma_{/t/})$)---set to match the average of the C-CuRE normalized category means and covariance matrices obtained from the data in @chodroff-wilson2018, and indicated by black points. The four priors differ, however, in their uncertainty about the category means and variances and thus in the changes they predict to occur when exposed to input from an unfamiliar talker. The more uncertain a listener is about the category means and variances of an unfamiliar talker (smaller $\kappa_{c,0}$ and $\nu_{c,0}$), the quicker that listener will adjust their expectations based on the inputs observed from that talker (see Figures \@ref(fig:demonstrate-changes-in-representations) and \@ref(fig:demonstrate-changes-in-representations-b)). Density lines are drawn at $10^{-3}$ to $10^{-10}$ at powers of 10. 

```{r demonstrate-niw-prior-mu-sigma, fig.width = base.width * 4, fig.height= base.height + 1, fig.cap="(ref:demonstrate-niw-prior-mu-sigma)", warning=FALSE}
plotlist = list(
  plot_VOT_NIW_belief_1D(m.ia.VOT %>% filter(prior_kappa == weak, prior_nu == weak, lambda == 0)),
  plot_VOT_NIW_belief_1D(m.ia.VOT %>% filter(prior_kappa == weak, prior_nu == strong, lambda == 0)),
  plot_VOT_NIW_belief_1D(m.ia.VOT %>% filter(prior_kappa == strong, prior_nu == weak, lambda == 0)),
  plot_VOT_NIW_belief_1D(m.ia.VOT %>% filter(prior_kappa == strong, prior_nu == strong, lambda == 0)))

my_plot_grid(plotlist = plotlist, legend.position = "top")
```

As listeners observe additional information from the unfamiliar talker, they update their beliefs (and thus uncertainty) about the distribution of that talker's category means and covariances. The updating of the four $\mathcal{NW^{-1}}$ parameters after $N$ observations of a category $c$ from the talker is described by the equations in \@ref(eq:niw-updating-parameters), and is deterministic [for details and derivation, see @murphy2012, p. 134]. $\kappa_c$ and $\nu_c$ simply increase by 1 with each observation, capturing the fact that each observation adds additional information about the talker's category mean and covariances. $\mathrm{m}_{N,c}$ is a weighted combination of its prior value $\mathrm{m}_{0,c}$ and the category mean of the $N$ observations $\bar{x}$---following the same logic that we applied to the inference of the overall cue mean in Equation \@ref(eq:normalization-change). Similarly, $\mathrm{S}_{N,c}$ is a weighted combination of its prior value $\mathrm{S}_{0,c}$ and the category variability of the $N$ observations,^[$\mathrm{S}_c \triangleq \Sigma_{i=1}^N x_{i,c} x_{i,c}^T$ is the uncentered sum of squares matrix of the $N$ observations [@murphy2012].] plus an additional term that captures the uncertainty about the category mean. The SI (\@ref(sec:SI-models-changes-in-representations)) summarizes the information in Equations \@ref(eq:niw-updating)-\@ref(eq:niw-updating-parameters) as a graphical model.

\begin{equation}\label{eq:niw-updating-parameters}
\begin{split}
\mathrm{m}_{N,c} & = \frac{\kappa_{0,c} \mathrm{m}_{0,c} + N \bar{x}}{\kappa_{N,c}} = \frac{\kappa_{0,c}}{\kappa_{0,c} + N} \mathrm{m}_{0,c} + \frac{N}{\kappa_{0,c} + N}\bar{x}_c \\
\kappa_{N,c} & = \kappa_{0,c} + N \\
\nu_{N,c} & = \nu_{0,c} + N \\
\mathrm{S}_{N,c} & = \mathrm{S}_{0,c} + \mathrm{S}_{\bar{x}_c} + \frac{\kappa_{0,c} N}{\kappa_{0,c} + N}\left( \bar{x}_c-\mathrm{m}_{0,c} \right) \left( \bar{x}_c-\mathrm{m}_{0,c} \right)^T \\
 & = \mathrm{S}_{0,c} + \mathrm{S}_c + \kappa_{0,c} \mathrm{m}_{0,c} \mathrm{m}_{0,c}^T - \kappa_{N,c} \mathrm{m}_{N,c} \mathrm{m}_{N,c}^T
\end{split}
\end{equation}

The $\kappa_{c}$s and $\nu_{c}$s are also sometimes called "pseudocounts" because they have a rather intuitive interpretation: the value of these parameters can be seen as describing the number of observations of this category that the listener assumes to have observed from the talker. For example, a listener with $\kappa_{c,0} = 100$ updates her beliefs about an unfamiliar talker's category mean as if she has already seen 100 observations of that category from the talker *prior to having received any input from that talker*. After 900 observations of that category from the unfamiliar talker, this listener's belief about the talker's category mean would be 10/90 mixture of the prior $\mathrm{m}_{c,0}$ and the mean of the 900 observed category instances $\bar{x}_c$. <!-- The extent to which listeners transfer prior expectations to an unfamiliar talker (i.e., the values of $\kappa_{c,0}$ and $\nu_{c,0}$) are expected to differ across phonological contrasts -->

Figures \@ref(fig:demonstrate-changes-in-representations) and \@ref(fig:demonstrate-changes-in-representations-b) further illustrate how speech input from a talker with unexpected pronunciations changes listeners' beliefs about the category likelihoods and, consequently, their categorization functions. We exposed the four models from Figure \@ref(fig:demonstrate-niw-prior-mu-sigma)---each of which reflects the expected category means and variances derived from Chodroff and Wilson (2018), but with different certainty---to input from a talker with unexpected pronunciations of /d/ and /t/. Specifically, the talker's /d/ and /t/ categories were shifted by +`r category_shift.demo` msecs VOT compared a (C-CuRE normalized) talker in Chodroff and Wilson' (2018) data. Additionally, the talker's /t/-category exhibited half the variance found in Chodroff and Wilson' data. Figure \@ref(fig:demonstrate-changes-in-representations) shows how the expected category likelihoods of the the four models change as a function of input from the new talker. Models with weak prior beliefs about category means ($\kappa_{0,c}=4$) accommodate the unfamiliar speech input by changing beliefs about the category mean---shifting categories 'horizontally'. Models with weak prior beliefs about category variance ($\nu_{0,c}=4$) accommodate the unfamiliar speech input by changing beliefs about the category variance---expanding the category. This is particularly apparent for the /d/ category. Figure \@ref(fig:demonstrate-changes-in-representations-b) demonstrates the consequences of these changes for the expected categorization function. 

<!-- \begin{figure} -->
  <!--   \centering -->
  <!--   \tikz{ % -->
      <!--     \node[obs] (cue) {$x_i$} ; % -->
      <!--     \factor[above=of cue] {cuedist} {left:$\mathcal{N}$} {} {}; % -->
      <!--     \node[obs, right=of cuedist] (category) {$c_i$} ; % -->
      <!--     \node[det, above=of cuedist] (mu) {$\mu_j$} ; % -->
      <!--     \node[det, right=of mu] (Sigma) {$\Sigma_j$} ; % -->
      <!--     \factor[above=of mu] {mudist} {left:$\mathcal{N}$} {} {}; % -->
      <!--     \factor[above=of Sigma] {Sigmadist} {left:$\mathcal{W}^{-1}$} {} {}; % -->
      <!--     \node[obs, above=of mudist] (m) {$m_j$} ; % -->
      <!--     \node[latent, left=of m] (kappa) {$\kappa_j$} ; % -->
      <!--     \node[latent, above=of Sigmadist] (nu) {$\nu_j$} ; % -->
      <!--     \node[obs, right=of nu] (S) {$S_j$} ; % -->
      <!--     \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate1} {(cue) (category) (cuedist)} {I}; % -->
      <!--     \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate2} {(mu) (Sigma) (mudist) (Sigmadist) (kappa) (m) (nu) (S)} {J}; % -->
      <!--     \edge {cuedist} {cue} ; % -->
      <!--     \edge {category} {cuedist} ; % -->
      <!--     \edge {mu, Sigma} {cuedist} ; % -->
      <!--     \edge {Sigma} {mudist} ; % -->
      <!--     \edge {kappa,m} {mudist} ; % -->
      <!--     \edge {nu,S} {Sigmadist} ; % -->
      <!--     \edge {mudist} {mu} ; % -->
      <!--     \edge {Sigmadist} {Sigma} ; % -->
      <!--   } -->
  <!--   \caption{A multivariate extension of the ideal adaptor model described in Kleinschmidt and Jaeger (2015). The model describes Bayesian belief-updating over multivariate Gaussian categories using a Normal-Inverse-Wishart ($\mathcal{NW}^{-1}$) prior. Filled circles indicate variables that are observable by the researcher, empty circles indicate variables that have to be inferred, and diamonds indicate variables that are determined by other the other variables. The model describes learning of the category likelihoods for $J$ categories based on $I$ observations (e.g., during an exposure phase of an experiment). For each observation, the category label $c_i$ and the cues $x_i$ are observed by the researcher (and the listener). In practice, two of the four parameters of the }\label{fig:niw} -->
  <!-- \end{figure} -->

(ref:demonstrate-changes-in-representations) Illustrating the effects of $\kappa_{c,0}$ and $\nu_{c,0}$ on changes in the expected category likelihoods, assuming a binary phonetic contrast between two Gaussian categories (`r paste0(categories.demo, collapse = "-")`) along a unidimensional continuum (VOT). Updating is shown for the data points in the rug along the x-axis: `r n.demo` observations each of `r paste(categories.demo, collapse = "and")` from a talker who realized both categories with a shifted mean of `r category_shift.demo` msec, and exhibits typical variance for `r categories.demo[1]` but only half of the typical variance for `r categories.demo[2]`. We set the lapse rate $\lambda = 0$ and response biases to uniform ($\pi_{0,c}=.5$). Animation controls require Acrobat PDF reader.

```{r demonstrate-changes-in-representations-preparation, message=FALSE, warning=FALSE}
my_groups <- c("prior_kappa", "prior_nu")

d.exposure <- 
  d.exposure.demo %>%
  crossing(
    m.ia.VOT %>% 
      filter(lambda == 0) %>%
      nest(prior = -all_of(my_groups))) %>%
  mutate(
    posterior = map2(
      data, 
      prior,
      ~ update_NIW_ideal_adaptor_incrementally(
        prior = .y,
        exposure = .x,
        exposure.category = "category",
        exposure.cues = cue.demo,
        noise_treatment = "marginalize",
        lapse_treatment = "marginalize",
        method = "label-certain",
        keep.update_history = T, 
        keep.exposure_data = T))) %>%
  select(-prior) %>%
  unnest(posterior) %>%
  nest(posterior = -c(data, all_of(my_groups), starts_with("observation"))) %>%
  mutate(
    mu1 = map(posterior, ~ .x$m[1]) %>% unlist(),
    mu2 = map(posterior, ~ .x$m[2]) %>% unlist(),
    sigma1 = map(posterior, ~ get_expected_Sigma_from_S(.x$S, .x$nu)[1]) %>% unlist(),
    sigma2 = map(posterior, ~ get_expected_Sigma_from_S(.x$S, .x$nu)[2]) %>% unlist()) 

d.exposure %<>%
  mutate(
    posterior.likelihood1 = map2(mu1, sigma1, ~ function(x) dnorm(x, .x, .y^.5)),
    posterior.likelihood2 = map2(mu2, sigma2, ~ function(x) dnorm(x, .x, .y^.5)),
    posterior.categorization_function = map(
      posterior, 
      ~ get_categorization_function_from_NIW_ideal_adaptor(.x, noise_treatment = "marginalize")))
```

```{r demonstrate-changes-in-representations, fig.width=base.width*2*1.5, fig.height=base.height + 1, fig.cap="(ref:demonstrate-changes-in-representations)", fig.show='animate'}
d.exposure %>%
  ggplot(aes(x = !! sym(cue.demo))) +
  # categorization function
  geom_line(
    data = . %>% 
      distinct(!!! syms(my_groups), posterior.likelihood1, posterior.likelihood2, observation.n) %>%
      crossing(category = categories.demo, !! sym(cue.demo) := seq(VOT_range[1], VOT_range[2])) %>%
      ungroup() %>%
      mutate(y = ifelse(
        category == categories.demo[1],
        map2(posterior.likelihood1, !! sym(cue.demo), .f = mycall) %>% unlist(),
        map2(posterior.likelihood2, !! sym(cue.demo), .f = mycall) %>% unlist())),
    aes(y = y, color = category, 
        alpha = factor(paste(!! sym(my_groups[2]), sep = ", ")), 
        group = paste(category, !!! syms(my_groups), observation.n))) +
  # background rug
  geom_rug(
    data = . %>%
      filter(!is.na(observation.category)) %>%
      distinct(!! sym(paste0("observation.", cue.demo)), observation.category),
    aes(x = !! sym(paste0("observation.", cue.demo)), color = observation.category),
    alpha = .4) +
  # current rug
  geom_rug(
    data = . %>%
      filter(!is.na(observation.category)),
    aes(x = !! sym(paste0("observation.", cue.demo)), color = observation.category),
    size = 2) +
  scale_x_continuous("VOT (msec)") +
  scale_y_continuous("Density") +
  scale_color_manual("Category", values = colors.voicing) +
  scale_alpha_manual(name = expression(nu[0~",c"]), values = c(.4, .8)) +
  facet_grid(
    . ~ prior_kappa,
    labeller = label_bquote(
      cols = {kappa[0~","~ .(categories.demo[1])] == kappa[0~","~ .(categories.demo[2])]} == .(as.character(prior_kappa)))) +
  theme(plot.margin = margin(t = 5, r = 0, b = 0, l = 20, unit = "pt"), legend.position = "top", panel.grid = element_blank()) +
  # ease_aes('linear') +
  # enter_fade() + exit_fade() +
  transition_states(observation.n, state_length = .5, transition_length = .5)
```

(ref:demonstrate-changes-in-representations-b) Changes in expected categorization functions resulting from the changes in the expected category likelihoods in Figure \@ref(fig:demonstrate-changes-in-representations). We set the lapse rate $\lambda = 0$, the prior lapse biases to uniform ($\pi_{0,c}=.5$). Neither normalization, nor response biases changed as a function of the input. Animation controls require Acrobat PDF reader.

```{r demonstrate-changes-in-representations-b, fig.width=base.width*2*1.5, fig.height=base.height + 1, fig.cap="(ref:demonstrate-changes-in-representations-b)", warning=FALSE, message=FALSE, fig.show='animate'}
d.exposure %>%
  ggplot(aes(x = !! sym(cue.demo))) +
  # categorization function
  geom_line(
    data = . %>% 
      distinct(!!! syms(my_groups), posterior.categorization_function, observation.n) %>%
      crossing(!! sym(cue.demo) := seq(VOT_range[1], VOT_range[2])) %>%
      mutate(y = map2(posterior.categorization_function, !! sym(cue.demo), .f = mycall) %>% unlist()),
    aes(y = y, alpha = factor(paste(!! sym(my_groups[2]), sep = ", ")), group = paste(!!! syms(my_groups), observation.n)), 
    color = "black") +
  # background rug
  geom_rug(
    data = . %>%
      filter(!is.na(observation.category)) %>%
      distinct(!! sym(paste0("observation.", cue.demo)), observation.category),
    aes(x = !! sym(paste0("observation.", cue.demo)), color = observation.category),
    alpha = .4) +
  # current rug
  geom_rug(
    data = . %>%
      filter(!is.na(observation.category)),
    aes(x = !! sym(paste0("observation.", cue.demo)), color = observation.category),
    size = 2) +
  scale_x_continuous("VOT (msec)") +
  scale_y_continuous("Posterior probability of /d/") +
  scale_color_manual("Category", values = colors.voicing) +
  scale_alpha_manual(name = expression(nu[0~",c"]), values = c(.4, .8)) +
  facet_grid(
    . ~ prior_kappa,
    labeller = label_bquote(
      cols = {kappa[0~","~ .(categories.demo[1])] == kappa[0~","~ .(categories.demo[2])]} == .(as.character(prior_kappa)))) +
  theme(plot.margin = margin(t = 5, r = 0, b = 0, l = 20, unit = "pt"), legend.position = "top", panel.grid = element_blank()) +
  # ease_aes('linear') +
  # enter_fade() + exit_fade() +
  transition_states(observation.n, state_length = .5, transition_length = .5)
```
  
## Modeling *changes* in decision-making {#sec:change-bias}
Finally, we specify a linking hypothesis for changes in response biases. To the best of our knowledge, this problem has not previously been formalized, or at least not for speech perception. Initially, we considered two conceptual models, both of which describe changes in response biases that only depend on the category label rather than the specific speech input. One possibility assumes that listeners aim to infer the relative probability of each category based on recent input, and that response biases reflect these estimates. For example, listeners might enter an experiment with expectations about the relative probability of each category based on their relative frequency in previously experienced input, and then update their expectations based on the relative frequency of the categories within the experiment [cf. belief-updating models of syntactic adaptation, @fine-jaeger2013; @jaeger2019; @prasad2021]. It is, however, clear that such a model could not possibly explain the exposure-based effects typically observed in, for example, perceptual recalibration experiments. In typical variants of those experiments, the relative frequency of the two categories does not differ between exposure conditions.

A second possibility is more plausible: listeners might adapt their response biases based on the categorization errors they make. Consider a typical experiment on accent adaptation. A listener unfamiliar with the target L2 accent will initially miscategorize inputs. Typically, these errors will not be random, but rather exhibit directionality. For example, in experiments on Mandarin-accented English, L1-English participants initially mishear voiced syllable-final stops as voiceless [e.g., hearing *lid* as *lit*, @flege1992; @xie2016jep]. Since experiments of this type employ exposure stimuli that effectively label the input category (e.g., *lemona_e*), these mistakes will often become apparent to the participant. Listeners who repeatedly observe themselves making such errors could thus increase the bias for the category that they keep failing to observe (/d/ in this example).^[We thank Zach Burchill for bringing this possibility to our attention.] The idea described here is captured by error-based learning models, including connectionist [e.g., @rumelhart-mcclelland1986; @mcclelland-elman1986], Bayesian [@jaeger-snider2013; @jaeger2019], and predictive coding models [e.g., @sohoglu2012; @rao-ballard1999; for review, see @clark2013]. Here we use a highly simplified version of such a linking hypothesis. Each time an input labeled as category $c$ is not heard as category $c$ (i.e., $\epsilon\mathrm{:}\ c \rightarrow \neg c$), the log-odds for category $c$ are increased by a constant amount $\beta_{\pi}$. And each time, an input that is labeled as another category is heard as category $c$ (i.e., $\epsilon\mathrm{:}\ \neg c \rightarrow c$), the log-odds for category $c$ are *de*creased by the same constant amount $\beta$. Thus, after $n$ observations with $n_{\epsilon\mathrm{:}\ c \rightarrow \neg c} + n_{\epsilon\mathrm{:}\ \neg c \rightarrow c}$ errors:

\begin{equation}\label{eq:bias-updating}
\begin{split}
\mathrm{logit}(\pi_{n,c}) & = \mathrm{logit}(\pi_{0,c}) + \beta_{\pi} n_{\epsilon\mathrm{:}\ c \rightarrow \neg c} - \beta_{\pi} n_{\epsilon\mathrm{:}\ \neg c \rightarrow c} \\
                          & = \mathrm{logit}(\pi_{0,c}) + \beta_{\pi} (n_{\epsilon\mathrm{:}\ c \rightarrow \neg c} - n_{\epsilon\mathrm{:}\ \neg c \rightarrow c}) \\
                          & := \mathrm{logit}(\pi_{0,c}) + \beta_{\pi} \delta_{\epsilon} \\
\end{split}
\end{equation}
                          <!-- & = \mathrm{logit}(\pi_{0,c}) + \beta \delta_{n_{\epsilon: c \rightarrow \neg c}} -->

where $\delta_\epsilon$ is a shorthand for the difference in the two error counts, and $\pi_{0,c}$ is the initial bias prior to any exposure. In the case studies presented below, we assume a uniform initial bias across all categories, leaving $\beta_{\pi}$ as the only degree of freedom. For the simple case of a 2AFC task, changes in the bias after $n$ observations are described by a logistic regression with intercept $\mathrm{logit}(\pi_{0,c})$ and slope $\beta_{\pi}$:

\begin{equation}\label{eq:bias-probability}
\begin{split}
\pi_{n,c} = \mathrm{logit}^{-1}\frac{1}{1+ e^{\mathrm{logit}(\pi_{0,c}) + \beta_{\pi} \delta_{\epsilon}}}
\end{split}
\end{equation}


This is the change model for response biases we assume in the remainder of the paper. Figure \@ref(fig:demonstrate-lapse-bias-change) illustrates this change model for three different values of $\beta_\pi$ when the lapse rate $\lambda=0$. The input to this model is identical to the one used in the previous section to demonstrate changes in representations. The right panel highlights a notable limitation in the types of results that can be explained through changes in responses biases: in the absence of lapses, changes in response biases can only explain *additive* effects on the log-odds of the categories, but not changes in the *slope* of the categorization function (in log-odds). To see how this limitation arises, how the *log-odds* of a category---e.g., /d/---in in Equation \@ref(eq:posterior-probability-lapse) depend on the responses biases $\pi$:


\begin{equation}\label{eq:posterior-probability-lapse-PR}
\begin{split}
p(/d/ | input) & = \frac{\mathcal{N}\!\left( input | \mu_{/d/}, \Sigma_{/d/} \right) \pi_{/d/}}{\Sigma_i \mathcal{N}\!\left( input | \mu_{c_i}, \Sigma_{c_i}\right) \pi_i} \Rightarrow \\
\log \frac{p(/d/ | input)}{1 - p(/d/ | input)} & =  \\
\log \frac{p(/d/ | input)}{p(/t/ | input)} & =  \log \frac{\mathcal{N}\!\left( input | \mu_{/d/}, \Sigma_{/d/} \right) \pi_{/d/}}{\mathcal{N}\!\left( input | \mu_{/t/}, \Sigma_{/t/} \right) \pi_{/t/}} \\
 & = \log \frac{\mathcal{N}\!\left( input | \mu_{/d/}, \Sigma_{/d/} \right)}{\mathcal{N}\!\left( input | \mu_{/t/}, \Sigma_{/t/} \right)} + \log\frac{\pi_{/d/}}{\pi_{/t/}}
\end{split}
\end{equation}

In other words, changes in response biases have additive effects on the log-odds of /d/ when $\lambda = 0$: adding some arbitrary amount to $\pi_{/d/}$ in Equation \@ref(eq:posterior-probability-lapse-PR) and subtracting same amount from $\pi_{/t/}$ (since $\Sigma_i \pi_i = 1$) will lift/lower the entire categorization function up or down by a constant amount, independent of the stimulus. This property does not depend on the specific change model assumed in Equation \@ref(eq:bias-probability). Regardless of the specific way in which response biases change as a function of the input, these changes should have additive effects on the posterior log-odds. 
<!-- We have heard this constraint informally summarized as "differences in response biases can only explain boundary shifts, but not changes in the slope of the categorization function". -->
Note, however, that this constraint only applies if $\lambda = 0$. For $\lambda \neq 0$, changes in response biases can lead to non-additive changes in the posterior log-odds.^[Specifically: $\log \frac{p(/d/ | input)}{p(/t/ | input)} = \log \frac{(1-\lambda)\mathcal{N}\!\left( input | \mu_{/d/}, \Sigma_{/d/} \right) + \lambda \left(\Sigma_i \mathcal{N}\!\left( input | \mu_{i}, \Sigma_{i} \right)\pi(c_i)\right)}{(1-\lambda)\mathcal{N}\!\left( input | \mu_{/t/}, \Sigma_{/t/} \right) + \lambda \left(\Sigma_i \mathcal{N}\!\left( input | \mu_{i}, \Sigma_{i} \right)\pi(c_i)\right)} + \log\frac{\pi_{/d/}}{\pi_{/t/}}$.] This is illustrated in Figure \@ref(fig:demonstrate-lapse-bias-change-nonzero-lapse). Changes in the slope of the categorization function (even in log-odds) therefore do *not* rule out explanations in terms of changing response biases, unless it is also shown that the lapse rate is 0.

(ref:demonstrate-lapse-bias-change) Illustrating the effects of $\beta_{\pi}$ on changes in the categorization function (**Left:** posterior probability, **Right:** posterior log-odds). The model has the same uncertain prior beliefs about category mean and variances as the model in Figure \@ref(fig:demonstrate-niw-prior-mu-sigma)D ($\kappa_{0,c} = \nu_{0,c}=0$). Neither normalization nor prior beliefs about the categories changes as a function of exposure. We set the lapse rate $\lambda = 0$, the prior lapse biases to uniform ($\pi_{0,c}=.5$). The input to this change model is identical to what was used in Figures \@ref(fig:demonstrate-changes-in-representations) and \@ref(fig:demonstrate-changes-in-representations-b). Orange arrows indicate the distance between the posterior log-odds resulting from the two most extreme $\beta_{\pi}$s. This highlights the fact that changes to responses biases have additive effects on the log-odds of `r categories.demo[1]` responses when $\lambda = 0$. Animation controls require Acrobat PDF reader.

```{r demonstrate-lapse-bias-change, fig.width=base.width*2.5 + 1.5, fig.height=base.height + .5, fig.cap="(ref:demonstrate-lapse-bias-change)", fig.show='animate', warning=FALSE, message=FALSE}
d.exposure <- 
  d.exposure.demo %>%
  crossing(
    beta = c(0.1, 0.5, 1),
    prior = list(m.ia.VOT %>% filter(lambda == 0, prior_kappa == strong, prior_nu == strong))) %>%
  mutate(
    posterior = pmap(
      .l = list(data, prior, beta),
      .f = function(.data, .prior, .beta)
        update_NIW_response_bias_incrementally(
          prior = .prior,
          beta = .beta,
          exposure = .data, 
          exposure.cues = cue.demo, 
          decision_rule = "proportional",
          noise_treatment = "marginalize",
          lapse_treatment = "marginalize",
          keep.exposure_data = T,
          keep.update_history = T))) %>%
  select(-prior) %>%
  crossing(use_logit = c(T, F)) %>%
  unnest(posterior) %>%
  nest(posterior = -c(data, beta, use_logit, starts_with("observation")))

d.exposure %<>%
  mutate(
    posterior.categorization_function = map2(
      posterior, 
      use_logit, 
      ~ get_categorization_function_from_NIW_ideal_adaptor(.x, logit = .y, noise_treatment = "marginalize")))

p <- 
  d.exposure %>%
  filter(!is.na(observation.category)) %>%
  mutate(use_logit = factor(ifelse(use_logit, "log-odds", "probability"), levels = c("probability", "log-odds"))) %>%
  ggplot(aes(x = !! sym(cue.demo))) +
  # categorization function
  geom_line(
    data = . %>% 
      distinct(beta, use_logit, posterior.categorization_function, observation.n) %>%
      crossing(!! sym(cue.demo) := seq(VOT_range[1], VOT_range[2])) %>%
      mutate(y = map2(posterior.categorization_function, !! sym(cue.demo), .f = mycall) %>% unlist()),
    aes(y = y, alpha = factor(beta), group = paste(beta, observation.n, use_logit)), color = "black") +
  # background rug
  geom_rug(
    data = . %>%
      distinct(!! sym(paste0("observation.", cue.demo)), observation.category),
    aes(x = !! sym(paste0("observation.", cue.demo)), color = observation.category),
    alpha = .4) +
  # current rug
  geom_rug(
    aes(x = !! sym(paste0("observation.", cue.demo)), color = observation.category),
    size = 2) +
  # labels
  geom_segment(
    data = . %>%
      distinct(beta, use_logit, posterior.categorization_function, observation.n) %>%
      filter(
        beta %in% range(beta),
        use_logit == "log-odds") %>%
      crossing(!! sym(cue.demo) := seq(VOT_range[1], VOT_range[2])) %>%
      filter(!! sym(cue.demo) %in% range(!! sym(cue.demo)))%>%
      mutate(y = map2(posterior.categorization_function, !! sym(cue.demo), .f = mycall) %>% unlist()) %>%
      group_by(use_logit, observation.n, !! sym(cue.demo)) %>%
      arrange(beta) %>%
      summarise(
        ymax = max(y),
        ymin = min(y)),
    aes(
      x = ifelse(!! sym(cue.demo) == max(!! sym(cue.demo)), !! sym(cue.demo) + 3, !! sym(cue.demo) - 3), 
      xend = ifelse(!! sym(cue.demo) == max(!! sym(cue.demo)), !! sym(cue.demo) + 3, !! sym(cue.demo) - 3),
      y = ymin,
      yend = ymax), 
    arrow = arrow(type = "closed", ends = "both", angle = 30, length = unit(0.05, "inches")),
    color = "orange", show.legend = F) +
  geom_text(
    data = . %>%
      distinct(beta, use_logit, posterior.categorization_function, observation.n) %>%
      crossing(!! sym(cue.demo) := seq(VOT_range[1], VOT_range[2])) %>%
      filter(
        beta %in% range(beta),
        !! sym(cue.demo) %in% range(!! sym(cue.demo)))%>%
      mutate(y = map2(posterior.categorization_function, !! sym(cue.demo), .f = mycall) %>% unlist()) %>%
      group_by(use_logit, observation.n, !! sym(cue.demo)) %>%
      arrange(beta) %>%
      summarise(
        ymax = max(y),
        y = max(y) - min(y)),
    aes(
      x = ifelse(!! sym(cue.demo) == max(!! sym(cue.demo)), !! sym(cue.demo) +6, !! sym(cue.demo) -6), 
      y = ymax - y/2, 
      label = ifelse(use_logit == "log-odds", round(y, ifelse(use_logit == "log-odds", 1, 2)), ""), 
      hjust = ifelse(!! sym(cue.demo) == max(!! sym(cue.demo)), 0, 1)),
    color = "orange", show.legend = F) +
  scale_x_continuous("VOT (msec)") +
  scale_y_continuous("Posterior of /d/") +
  scale_color_manual("Category", values = colors.voicing) +
  scale_alpha_manual(name = expression(beta[pi]), values = c(.2, .5, .8)) +
  coord_cartesian(xlim = VOT_range + c(-15, 15)) +
  facet_wrap(~ use_logit, scales = "free_y") +
  theme(plot.margin = margin(t = 5, r = 0, b = 0, l = 20, unit = "pt"), legend.position = "right", panel.grid = element_blank()) +
  transition_states(observation.n, state_length = .5, transition_length = .5)

p
```

(ref:demonstrate-lapse-bias-change-nonzero-lapse) Same as Figure \@ref(fig:demonstrate-lapse-bias-change) but for a lapse rate $\lambda=$ `r lambdas.demo[2]`. For such non-zero lapse rates, changes to the response bias have *non*-additive effects on the posterior log-odds. This means that, even in log-odds, changes in response biases can have effects that go beyond *shifts* in category boundaries. Animation controls require Acrobat PDF reader.

```{r demonstrate-lapse-bias-change-nonzero-lapse, fig.width=base.width*2.5 + 1.5, fig.height=base.height +.5, fig.cap="(ref:demonstrate-lapse-bias-change-nonzero-lapse)", fig.show='animate', warning=FALSE, message=FALSE}
d.exposure <- 
  d.exposure.demo %>%
  crossing(
    beta = c(0.1, 0.5, 1),
    prior = list(m.ia.VOT %>% filter(lambda == lambdas.demo[2], prior_kappa == strong, prior_nu == strong))) %>%
  mutate(
    posterior = pmap(
      .l = list(data, prior, beta),
      .f = function(.data, .prior, .beta)
        update_NIW_response_bias_incrementally(
          prior = .prior,
          beta = .beta,
          exposure = .data, 
          exposure.cues = cue.demo, 
          decision_rule = "proportional",
          noise_treatment = "marginalize",
          lapse_treatment = "marginalize",
          keep.exposure_data = T,
          keep.update_history = T))) %>%
  select(-prior) %>%
  crossing(use_logit = c(T, F)) %>%
  unnest(posterior) %>%
  nest(posterior = -c(data, beta, use_logit, starts_with("observation")))

d.exposure %<>%
  mutate(
    posterior.categorization_function = map2(
      posterior, 
      use_logit, 
      ~ get_categorization_function_from_NIW_ideal_adaptor(.x, logit = .y, noise_treatment = "marginalize")))

p %+% 
  (d.exposure %>%
  filter(!is.na(observation.category)) %>%
  mutate(use_logit = factor(ifelse(use_logit, "log-odds", "probability"), levels = c("probability", "log-odds"))))
```

Next, we present two case studies that illustrate the predictions of the three change models for perceptual recalibration (Case Study 1) and accent adaptation (Case Study 2).

```{r MVG-make-models}
cues <- c("VOT_centered", "f0_Mel_centered")

prior_marginal_VOT_f0_stats <- 
  d.chodroff_wilson %>%
  group_by(Talker) %>%
  summarise(across(c(VOT, f0_Mel), mean)) %>%
  ungroup() %>%
  summarise(
    x_mean = list(c(VOT = mean(VOT), f0 = mean(f0_Mel))),
    x_var_VOT = var(VOT),
    x_var_f0 = var(f0_Mel),
    x_cov = list(cov(cbind(VOT, f0_Mel))))

m.VOT_f0_MVG <- 
  make_MVG_from_data(
  data = d.chodroff_wilson,
  category = "category",
  cues = cues) 
```
