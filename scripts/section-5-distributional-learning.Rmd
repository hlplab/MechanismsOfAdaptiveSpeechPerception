
# Distributional learning paradigms

```{r study-DL-setup, message=FALSE}
# Which categories is this experiment about?
categories.DL <- c("/b/", "/p/")
conditions.DL <- c("narrow", "wide")
colors.category <-colors.voicing 
colors.condition <- c("green", "orange")
shapes.category <- shapes.condition <- c(15, 17)
linetypes.condition <- c(1,2)

# Number of subjects
n.subject <- 1

# Number of exposure tokens for each category, shifted and typical
n.exposure.token <- 228 

# Number of test blocks
n.test_block <- 1

m.io.VOT_f0.DL <-
  m.VOT_f0_MVG  %>%
  filter(category %in% categories.DL) %>%
  droplevels() %>%
  make_stop_VOTf0_ideal_observer() %>%
  arrange(category)

m.ia.VOT_f0.DL <- 
  crossing(
    prior_kappa = 4^(1:5),
    prior_nu = 4^(1:5)) %>%
  rowwise() %>%
  mutate(
    ideal_adaptor = map2(prior_kappa, prior_nu, ~ make_stop_VOTf0_ideal_adaptor(m = m.io.VOT_f0.PR, kappa = .x, nu = .y))) %>%
  unnest(ideal_adaptor) %>%
  arrange(category)
```

The final class of paradigms we consider differs from the paradigms we have discussed so far in that it explicitly manipulates the distribution of cues. Examples of this type of paradigm are known as, for example, "distributional learning" e.g., [@clayards2008; @escudero-williams2014; @theodore2020], "(dimension-based) statistical learning" [e.g., @idemaru-holt2011; @liu-holt2015], or "cue (re) weighting" [e.g., @harmon2019; @schertz-clare2020; @toscano-mcmurray2010], although more general terms are also used [e.g., "perceptual learning", [e.g., @munson2011; @norris2003; @samuel-kraljic2009; @sidaras2009; @weatherholtz2015]. Beyond its use for research on the effects of recent exposure on the adult L1 listeners' perception, these paradigms have also been popular in research on first and second language acquisition [e.g., @saffran1996b; @yoshida2010; @vallabha2007a; @pajak-levy2014]. 

In these paradigms, listeners are exposed to distributions that differ between participants in their category means [@idemaru-holt2011; @kleinschmidt2015; @munson2011], (co)variances [@clayards2008; @nixon2016], or both [@burchill-jaeger2022; @REF]. Since shift in means lead to difference in cue distributions that are not unlike those that we have already discussed for perceptual recalibration paradigms, we focus our case study on manipulations of the category variance. In an important study, Clayards et al., [-@clayards2008] assigned participants to one of two conditions: one group heard `r paste(categories.DL, collapse = " and ")` categories with identical narrow variance along VOT; the other group heard `r paste(categories.DL, collapse = " and ")` categories with the same means as in the narrow variance group but with wide variance along VOT. The speech recordings were generated by a synthesizer [@klatt1986], and all other cues (including f0) were held constant across categories and conditions. Panel A of Figure \@ref(fig:DL-clayards) shows the two exposure conditions. On each trial, participants saw a display with 2 x 2 line drawings and had to click on the picture corresponding to the word they heard. The display always contained both members of a minimal pair corresponding to the recording participants heard (e.g., a drawing of bees and a drawing of peas). In this paradigm, exposure is thus unlabelled, and each trial serves both as exposure and test---unlike in the other two paradigms we have discussed. Clayards and colleagues ten fit a psychometric model with lapse and bias terms [@wichmann-hill2001] to all 228 trials from each participant to estimate the participant-specific categorization functions, and compared the average categorization functions across conditions (see Panel B of Figure \@ref(fig:DL-clayards)).^[We thank Meghan Clayards for sharing with us the raw data from Clayards et al., [-@clayards2008].]

(ref:DL-clayards) Panel A: VOT distributions of the two conditions employed in @clayards2008. Both conditions exposed participants to 228 synthesized word recordings along the VOT continuum. The two conditions differed in the variance around the two modes of the VOT distribution. Panel B: Results of @clayards2008. Means and 95% bootstrapped confidence intervals over by-participant means. The effect on the slope of the categorization function was small but significant: participants in the wide variance condition exhibited more shallow categorization curves.

```{r DL-clayards, fig.width=2*3 + 1, fig.height=2.5, fig.cap="(ref:DL-clayards)"}
d.clayards <- read_delim("../../data/Clayards-Tanenhaus-Aslin-Jacobs-2008/cognition_trialbytrial_resp.txt", delim = "\t") %>%
  mutate(condition = plyr::mapvalues(condition, c("N", "W"), conditions.DL)) %>%
  rename(Condition = condition, Subject = subject, Trial = trial) %>%
  group_by(Subject) %>%
  mutate(
    response = 1 - response, # to make response 1 if voiced for parallelism to rest of document
    Trial = as.numeric(factor(Trial)))

plot_grid(
  d.clayards %>%
    group_by(Condition, VOT) %>%
    tally() %>%
    distinct(Condition, VOT, n) %>%
    ggplot(aes(x = VOT, y = n, fill = Condition)) +
    geom_bar(stat = "identity", show.legend = FALSE) +
    scale_x_continuous(expression("VOT (ms)")) +
    scale_y_continuous("number of trials") +
    scale_fill_manual(breaks = conditions.DL, values = colors.condition) +
    facet_grid(~ Condition),
  d.clayards %>%
    group_by(Condition, Subject, VOT) %>%
    summarise(proportion_voiced = mean(response)) %>%
    ggplot(aes(x = VOT, y = proportion_voiced, color = Condition)) +
    stat_summary(fun.data = mean_cl_boot, geom = "pointrange", position = position_dodge(3)) +
    stat_summary(fun = mean, geom = "line", position = position_dodge(3)) +
    scale_x_continuous(expression("VOT (ms)")) +
    scale_y_continuous("Proportion /b/-responses") +
    scale_color_manual(breaks = conditions.DL, values = colors.condition) +
    theme(plot.margin = margin(t = 0, r = 0, b = 0, l = 10, unit = "pt"), legend.position = "top"),
  labels = c("A)", "B)"),
  align = "hv", axis = "tb")
```

## Methods

STATE THAT WE SET F0 TO MEAN OF CHODROFF DATA

Both supervised [@bejjanki2011; @kleinschmidt2015] and unsupervised exposure [@clayards2008; @munson2011; @nixon2016] has been employed in distributional learning paradigms. In the former, each stimulus is lexically or otherwise labeled for the category it contains; in the latter, listeners have to infer categories' cue distributions solely from the multi-modality of the input, potentially combined with prior expectations about the relative order of categories in the phonetic space. Here, we simulate a supervised paradigm to avoid the additional complexities that come with predicting unsupervised learning.^[Unsupervised learning models exist for L1 acquisition [e.g., @feldman2013; @mcmurray2007, @toscano-mcmurray2010]. However, the extension of these models to perceptual learning in adults, who have already formed category representations, requires additional considerations [e.g., @yan-jaeger2017] that go beyond the scope of the present work.] To the best of our knowledge, only one previous study has directly compared the effects of labeled and unlabeled inputs for this type of paradigm [@kleinschmidt2015]. Kleinschmidt and colleagues used the same stimuli as Clayards et al. (2008) to expose participants to bimodal VOT distributions that were shifted by 10, 20, 30, or 40 ms relative to listeners' prior expectations. Exposure was either always unlabeled (as in Clayards et al., [-@clayards2008] or was labeled on about XXX% of the trials. Kleinschmidt and colleagues found that category boundaries were shifted further, the further the VOT distributions had been shifted---a finding that could be explained by any of the three theories considered here. They did not, however, find any difference between the fully unlabeled and the semi-labeled conditions. A follow-up analysis of the same data by Yan and Jaeger (2017) found small difference between fully unlabeled and the semi-labeled during the early trials of the experiment but these differences dissipated with increasing exposure. 

SAY WHY RELEVANT

## Models

We again use the general model of perceptual decision-making to illustrate to what extent changes in normalization, representations, or response biases can explain the findings like those obtained by Clayards et al., [-@clayards2008]: changes in the slope of the categorization function.

```{r study-DL-make-exposure-data}
mu_b <- 0
mu_p <- 50
sigma_narrow <- 8
sigma_wide <- 14

# This approach takes one subject and shuffles it. It is an alternative to the 'average' subject used above
d.DL.exposure <- 
  # Get unique VOT locations
  d.clayards %>%
  group_by(Condition) %>%
  filter(Subject == first(Subject)) %>%
  # Tally and distribute VOT locations across the two categories
  group_by(Condition, Subject, VOT) %>%
  tally() %>%
  mutate(
    sigma = ifelse(Condition == "narrow", sigma_narrow, sigma_wide),
    `/b/` = pmap(
      .l = list(VOT, sigma, n),
      .f = function(VOT, sigma, n) 
        round(n * dnorm(VOT, mu_b, sigma) / (dnorm(VOT, mu_b, sigma) + dnorm(VOT, mu_p, sigma)))) %>%
      unlist(),
    `/p/` = n - `/b/`,
    n = NULL,
    sigma = NULL) %>%
  pivot_longer(
    cols = c(`/b/`, `/p/`),
    names_to = "Item.Category",
    values_to = "n") %>%
  # Add f0 information
  mutate(
    f0_Mel = prior_marginal_VOT_f0_stats$x_mean[[1]][2],
    x = map2(VOT, f0_Mel, ~ c(.x, .y)))

# Make one row per observation
d.DL.exposure <- d.DL.exposure[rep(seq(nrow(d.DL.exposure)), d.DL.exposure$n), ] %>%
  mutate(n = NULL) %>%
  # Shuffle exposure (just for fun)
  slice_sample(prop = 1, replace = F)
```


<!-- ### Changes in representations -->

<!-- ```{r study-DL-models-changes-in-representations} -->
<!-- # Check whether results exist since this takes a bit longer to run -->
<!-- if (file.exists(get_path("../model/posterior-categorizations-clayards.rds"))) { -->
<!--   d.DL <- readRDS(get_path("../model/posterior-categorizations-clayards.rds")) -->
<!-- } else { -->
<!--   # Add posterior and organize it by incremental update (observation.n) -->
<!--   d.DL <- -->
<!--     d.DL.exposure %>% -->
<!--     add_prior_and_get_posterior_beliefs_based_on_exposure(prior = m.ia.VOT_f0.DL, keep.update_history = T) %>% -->
<!--     # Get rid of prior (since it's the posterior of observation.n == 0) and re-group posterior by observation.n -->
<!--     select(-c(data, prior)) %>% -->
<!--     unnest(posterior) %>% -->
<!--     group_by(Condition, Subject, prior_kappa, prior_nu, observation.n) %>% -->
<!--     nest(posterior = c(category, m, S, kappa, nu, prior, Sigma_noise, lapse_rate, lapse_bias)) -->

<!--   d.DL %<>% -->
<!--     crossing(x = d.DL.exposure %>% pull(x) %>% unique()) %>% -->
<!--     nest(x = x) %>% -->
<!--     group_by(Condition, Subject, prior_kappa, prior_nu, observation.n) %>% -->
<!--     add_categorization() -->

<!--   saveRDS(d.DL, file = get_path("../models/posterior-categorizations-clayards.rds")) -->
<!-- } -->
<!-- ``` -->


<!-- BE CLEAR THAT THIS TYPE OF PATTERN CAN ONLY BE EXPLAINED THROUGH LEARNING IF IT'S CATEGORY EXPANSION. -->

<!-- Figure (fig:DL-result-changes-in-representations) shows the predicted categorization functions after `r paste(conditions.DL, collapse = " and ")` exposure, depending on the strength of the prior beliefs for the category means and variances. -->

<!-- (ref:DL-result-changes-in-representations) Predictions of a learning model that derives the results of Clayards et al. (2008) as changes in category representations. Predicted categorization responses are shown for the final of the 228 trials that participants saw, depending on the strength of the prior beliefs in categories means ($\kappa_0$) and covariances ($\nu_0$). Smaller $\kappa_0$ and $\nu_0$ indicate *faster* learning, weighting previous long-term experience less during the integration with the observations made during the exposure phase of the experiment. -->

<!-- ```{r study-DL-models-changes-in-representations-plots, fig.width=2*5, fig.height=2*5+.5, fig.cap="(ref:DL-result-changes-in-representations)"} -->
<!-- p.DL.results <- -->
<!--   d.DL %>% -->
<!--   mutate(VOT = map(x, ~ .x[1]) %>% unlist()) %>% -->
<!--   filter(category == categories.DL[1], observation.n == max(observation.n)) %>% -->
<!--   group_by(prior_kappa, prior_nu, Condition, VOT) %>% -->
<!--   summarise(response = mean(response)) %>% -->
<!--   ggplot(aes(x = VOT, y = response, color = Condition, linetype = Condition)) + -->
<!--   geom_line(aes(group = Condition), alpha = .75) + -->
<!--   scale_x_continuous(name = "Test token") + -->
<!--   scale_y_continuous(paste0('Proportion ', categories.DL[1], '-responses'), limits = c(0, 1)) + -->
<!--   scale_linetype_manual("Exposure condition", breaks = conditions.DL, values = linetypes.condition) + -->
<!--   scale_color_manual("Exposure condition", breaks = conditions.DL, values = colors.condition) + -->
<!--   facet_grid( -->
<!--     prior_nu ~ prior_kappa, -->
<!--     labeller = label_bquote( -->
<!--       cols = kappa[0] == ~.(prior_kappa), -->
<!--       rows = nu[0] == ~.(prior_nu))) + # as.table = T doesn't seem to work -->
<!--   theme(legend.position = "top") -->
<!-- p.DL.results -->
<!-- ``` -->

<!-- ```{r, fig.show='animate', warnings=FALSE} -->
<!-- library(gganimate) -->

<!-- observation.bins <- pmin(2^c(0:8), 228) -->
<!-- VOT_range <- c(0, 60) -->

<!-- p.DL.results <- -->
<!--   d.DL %>% -->
<!--   mutate(VOT = map(x, ~ .x[1]) %>% unlist()) %>% -->
<!--   filter( -->
<!--     category == categories.DL[1], -->
<!--     between(VOT, VOT_range[1], VOT_range[2]), -->
<!--     observation.n %in% observation.bins) %>% -->
<!--   ggplot(aes(x = VOT, y = response, color = Condition, linetype = Condition)) + -->
<!--   geom_smooth( -->
<!--     # plot smoother for responses in the trial bin *following* the corresponding posterior -->
<!--     data = d.clayards %>% -->
<!--       mutate(observation.n = cut(Trial, breaks = observation.bins, include.lowest = F, right = T, labels = observation.bins[1:(length(observation.bins)-1)])), -->
<!--     aes(y = response, fill = Condition), -->
<!--     method = "glm", method.args = list(family = binomial), -->
<!--     na.rm = T, color = NA, alpha = .3, fullrange = T) + -->
<!--   geom_line(aes(group = Condition), alpha = .75) + -->
<!--   scale_x_continuous(name = "Test token") + -->
<!--   scale_y_continuous(paste0('Proportion ', categories.DL[1], '-responses'), limits = c(0, 1)) + -->
<!--   scale_linetype_manual("Exposure condition", breaks = conditions.DL, values = linetypes.condition) + -->
<!--   scale_fill_manual("Exposure condition", breaks = conditions.DL, values = colors.condition) + -->
<!--   scale_color_manual("Exposure condition", breaks = conditions.DL, values = colors.condition) + -->
<!--   facet_grid( -->
<!--     prior_nu ~ prior_kappa, -->
<!--     labeller = label_bquote( -->
<!--       cols = kappa[0] == ~.(prior_kappa), -->
<!--       rows = nu[0] == ~.(prior_nu))) + # as.table = T doesn't seem to work -->
<!--   theme(legend.position = "top") + -->
<!--   coord_cartesian(xlim = VOT_range) + -->
<!--   ggtitle(label = 'Trial: {closest_state}') + -->
<!--   transition_states(states = observation.n) -->

<!-- p.DL.results -->
<!-- ``` -->
